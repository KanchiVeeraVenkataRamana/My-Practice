{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e754241",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1.040e+00, 3.920e+00,\n",
       "         1.065e+03],\n",
       "        [1.320e+01, 1.780e+00, 2.140e+00, ..., 1.050e+00, 3.400e+00,\n",
       "         1.050e+03],\n",
       "        [1.316e+01, 2.360e+00, 2.670e+00, ..., 1.030e+00, 3.170e+00,\n",
       "         1.185e+03],\n",
       "        ...,\n",
       "        [1.327e+01, 4.280e+00, 2.260e+00, ..., 5.900e-01, 1.560e+00,\n",
       "         8.350e+02],\n",
       "        [1.317e+01, 2.590e+00, 2.370e+00, ..., 6.000e-01, 1.620e+00,\n",
       "         8.400e+02],\n",
       "        [1.413e+01, 4.100e+00, 2.740e+00, ..., 6.100e-01, 1.600e+00,\n",
       "         5.600e+02]]),\n",
       " 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2]),\n",
       " 'frame': None,\n",
       " 'target_names': array(['class_0', 'class_1', 'class_2'], dtype='<U7'),\n",
       " 'DESCR': '.. _wine_dataset:\\n\\nWine recognition dataset\\n------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 178 (50 in each of three classes)\\n    :Number of Attributes: 13 numeric, predictive attributes and the class\\n    :Attribute Information:\\n \\t\\t- Alcohol\\n \\t\\t- Malic acid\\n \\t\\t- Ash\\n\\t\\t- Alcalinity of ash  \\n \\t\\t- Magnesium\\n\\t\\t- Total phenols\\n \\t\\t- Flavanoids\\n \\t\\t- Nonflavanoid phenols\\n \\t\\t- Proanthocyanins\\n\\t\\t- Color intensity\\n \\t\\t- Hue\\n \\t\\t- OD280/OD315 of diluted wines\\n \\t\\t- Proline\\n\\n    - class:\\n            - class_0\\n            - class_1\\n            - class_2\\n\\t\\t\\n    :Summary Statistics:\\n    \\n    ============================= ==== ===== ======= =====\\n                                   Min   Max   Mean     SD\\n    ============================= ==== ===== ======= =====\\n    Alcohol:                      11.0  14.8    13.0   0.8\\n    Malic Acid:                   0.74  5.80    2.34  1.12\\n    Ash:                          1.36  3.23    2.36  0.27\\n    Alcalinity of Ash:            10.6  30.0    19.5   3.3\\n    Magnesium:                    70.0 162.0    99.7  14.3\\n    Total Phenols:                0.98  3.88    2.29  0.63\\n    Flavanoids:                   0.34  5.08    2.03  1.00\\n    Nonflavanoid Phenols:         0.13  0.66    0.36  0.12\\n    Proanthocyanins:              0.41  3.58    1.59  0.57\\n    Colour Intensity:              1.3  13.0     5.1   2.3\\n    Hue:                          0.48  1.71    0.96  0.23\\n    OD280/OD315 of diluted wines: 1.27  4.00    2.61  0.71\\n    Proline:                       278  1680     746   315\\n    ============================= ==== ===== ======= =====\\n\\n    :Missing Attribute Values: None\\n    :Class Distribution: class_0 (59), class_1 (71), class_2 (48)\\n    :Creator: R.A. Fisher\\n    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\\n    :Date: July, 1988\\n\\nThis is a copy of UCI ML Wine recognition datasets.\\nhttps://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data\\n\\nThe data is the results of a chemical analysis of wines grown in the same\\nregion in Italy by three different cultivators. There are thirteen different\\nmeasurements taken for different constituents found in the three types of\\nwine.\\n\\nOriginal Owners: \\n\\nForina, M. et al, PARVUS - \\nAn Extendible Package for Data Exploration, Classification and Correlation. \\nInstitute of Pharmaceutical and Food Analysis and Technologies,\\nVia Brigata Salerno, 16147 Genoa, Italy.\\n\\nCitation:\\n\\nLichman, M. (2013). UCI Machine Learning Repository\\n[https://archive.ics.uci.edu/ml]. Irvine, CA: University of California,\\nSchool of Information and Computer Science. \\n\\n.. topic:: References\\n\\n  (1) S. Aeberhard, D. Coomans and O. de Vel, \\n  Comparison of Classifiers in High Dimensional Settings, \\n  Tech. Rep. no. 92-02, (1992), Dept. of Computer Science and Dept. of  \\n  Mathematics and Statistics, James Cook University of North Queensland. \\n  (Also submitted to Technometrics). \\n\\n  The data was used with many others for comparing various \\n  classifiers. The classes are separable, though only RDA \\n  has achieved 100% correct classification. \\n  (RDA : 100%, QDA 99.4%, LDA 98.9%, 1NN 96.1% (z-transformed data)) \\n  (All results using the leave-one-out technique) \\n\\n  (2) S. Aeberhard, D. Coomans and O. de Vel, \\n  \"THE CLASSIFICATION PERFORMANCE OF RDA\" \\n  Tech. Rep. no. 92-01, (1992), Dept. of Computer Science and Dept. of \\n  Mathematics and Statistics, James Cook University of North Queensland. \\n  (Also submitted to Journal of Chemometrics).\\n',\n",
       " 'feature_names': ['alcohol',\n",
       "  'malic_acid',\n",
       "  'ash',\n",
       "  'alcalinity_of_ash',\n",
       "  'magnesium',\n",
       "  'total_phenols',\n",
       "  'flavanoids',\n",
       "  'nonflavanoid_phenols',\n",
       "  'proanthocyanins',\n",
       "  'color_intensity',\n",
       "  'hue',\n",
       "  'od280/od315_of_diluted_wines',\n",
       "  'proline']}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn import datasets\n",
    "df=datasets.load_wine()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "83066162",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alcohol</th>\n",
       "      <th>malic_acid</th>\n",
       "      <th>ash</th>\n",
       "      <th>alcalinity_of_ash</th>\n",
       "      <th>magnesium</th>\n",
       "      <th>total_phenols</th>\n",
       "      <th>flavanoids</th>\n",
       "      <th>nonflavanoid_phenols</th>\n",
       "      <th>proanthocyanins</th>\n",
       "      <th>color_intensity</th>\n",
       "      <th>hue</th>\n",
       "      <th>od280/od315_of_diluted_wines</th>\n",
       "      <th>proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113.0</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   alcohol  malic_acid   ash  alcalinity_of_ash  magnesium  total_phenols  \\\n",
       "0    14.23        1.71  2.43               15.6      127.0           2.80   \n",
       "1    13.20        1.78  2.14               11.2      100.0           2.65   \n",
       "2    13.16        2.36  2.67               18.6      101.0           2.80   \n",
       "3    14.37        1.95  2.50               16.8      113.0           3.85   \n",
       "4    13.24        2.59  2.87               21.0      118.0           2.80   \n",
       "\n",
       "   flavanoids  nonflavanoid_phenols  proanthocyanins  color_intensity   hue  \\\n",
       "0        3.06                  0.28             2.29             5.64  1.04   \n",
       "1        2.76                  0.26             1.28             4.38  1.05   \n",
       "2        3.24                  0.30             2.81             5.68  1.03   \n",
       "3        3.49                  0.24             2.18             7.80  0.86   \n",
       "4        2.69                  0.39             1.82             4.32  1.04   \n",
       "\n",
       "   od280/od315_of_diluted_wines  proline  \n",
       "0                          3.92   1065.0  \n",
       "1                          3.40   1050.0  \n",
       "2                          3.17   1185.0  \n",
       "3                          3.45   1480.0  \n",
       "4                          2.93    735.0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "x=pd.DataFrame(data=df.data,columns=df.feature_names)\n",
    "y=pd.Series(data=df.target)\n",
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c3824dea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "dtype: int32"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "381750b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7cfbd10e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(142, 13)\n",
      "1846\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alcohol</th>\n",
       "      <th>malic_acid</th>\n",
       "      <th>ash</th>\n",
       "      <th>alcalinity_of_ash</th>\n",
       "      <th>magnesium</th>\n",
       "      <th>total_phenols</th>\n",
       "      <th>flavanoids</th>\n",
       "      <th>nonflavanoid_phenols</th>\n",
       "      <th>proanthocyanins</th>\n",
       "      <th>color_intensity</th>\n",
       "      <th>hue</th>\n",
       "      <th>od280/od315_of_diluted_wines</th>\n",
       "      <th>proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>12.72</td>\n",
       "      <td>1.81</td>\n",
       "      <td>2.20</td>\n",
       "      <td>18.8</td>\n",
       "      <td>86.0</td>\n",
       "      <td>2.20</td>\n",
       "      <td>2.53</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.77</td>\n",
       "      <td>3.90</td>\n",
       "      <td>1.16</td>\n",
       "      <td>3.14</td>\n",
       "      <td>714.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>14.39</td>\n",
       "      <td>1.87</td>\n",
       "      <td>2.45</td>\n",
       "      <td>14.6</td>\n",
       "      <td>96.0</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2.52</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.98</td>\n",
       "      <td>5.25</td>\n",
       "      <td>1.02</td>\n",
       "      <td>3.58</td>\n",
       "      <td>1290.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>12.64</td>\n",
       "      <td>1.36</td>\n",
       "      <td>2.02</td>\n",
       "      <td>16.8</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.02</td>\n",
       "      <td>1.41</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.62</td>\n",
       "      <td>5.75</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1.59</td>\n",
       "      <td>450.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>12.43</td>\n",
       "      <td>1.53</td>\n",
       "      <td>2.29</td>\n",
       "      <td>21.5</td>\n",
       "      <td>86.0</td>\n",
       "      <td>2.74</td>\n",
       "      <td>3.15</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.77</td>\n",
       "      <td>3.94</td>\n",
       "      <td>0.69</td>\n",
       "      <td>2.84</td>\n",
       "      <td>352.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>13.41</td>\n",
       "      <td>3.84</td>\n",
       "      <td>2.12</td>\n",
       "      <td>18.8</td>\n",
       "      <td>90.0</td>\n",
       "      <td>2.45</td>\n",
       "      <td>2.68</td>\n",
       "      <td>0.27</td>\n",
       "      <td>1.48</td>\n",
       "      <td>4.28</td>\n",
       "      <td>0.91</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1035.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     alcohol  malic_acid   ash  alcalinity_of_ash  magnesium  total_phenols  \\\n",
       "81     12.72        1.81  2.20               18.8       86.0           2.20   \n",
       "6      14.39        1.87  2.45               14.6       96.0           2.50   \n",
       "61     12.64        1.36  2.02               16.8      100.0           2.02   \n",
       "126    12.43        1.53  2.29               21.5       86.0           2.74   \n",
       "41     13.41        3.84  2.12               18.8       90.0           2.45   \n",
       "\n",
       "     flavanoids  nonflavanoid_phenols  proanthocyanins  color_intensity   hue  \\\n",
       "81         2.53                  0.26             1.77             3.90  1.16   \n",
       "6          2.52                  0.30             1.98             5.25  1.02   \n",
       "61         1.41                  0.53             0.62             5.75  0.98   \n",
       "126        3.15                  0.39             1.77             3.94  0.69   \n",
       "41         2.68                  0.27             1.48             4.28  0.91   \n",
       "\n",
       "     od280/od315_of_diluted_wines  proline  \n",
       "81                           3.14    714.0  \n",
       "6                            3.58   1290.0  \n",
       "61                           1.59    450.0  \n",
       "126                          2.84    352.0  \n",
       "41                           3.00   1035.0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(x_train.size)\n",
    "x_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bfbaab0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36, 13)\n",
      "468\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alcohol</th>\n",
       "      <th>malic_acid</th>\n",
       "      <th>ash</th>\n",
       "      <th>alcalinity_of_ash</th>\n",
       "      <th>magnesium</th>\n",
       "      <th>total_phenols</th>\n",
       "      <th>flavanoids</th>\n",
       "      <th>nonflavanoid_phenols</th>\n",
       "      <th>proanthocyanins</th>\n",
       "      <th>color_intensity</th>\n",
       "      <th>hue</th>\n",
       "      <th>od280/od315_of_diluted_wines</th>\n",
       "      <th>proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>12.36</td>\n",
       "      <td>3.83</td>\n",
       "      <td>2.38</td>\n",
       "      <td>21.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>2.30</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.04</td>\n",
       "      <td>7.65</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.58</td>\n",
       "      <td>520.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>13.84</td>\n",
       "      <td>4.12</td>\n",
       "      <td>2.38</td>\n",
       "      <td>19.5</td>\n",
       "      <td>89.0</td>\n",
       "      <td>1.80</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.48</td>\n",
       "      <td>1.56</td>\n",
       "      <td>9.01</td>\n",
       "      <td>0.57</td>\n",
       "      <td>1.64</td>\n",
       "      <td>480.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>12.33</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.95</td>\n",
       "      <td>14.8</td>\n",
       "      <td>136.0</td>\n",
       "      <td>1.90</td>\n",
       "      <td>1.85</td>\n",
       "      <td>0.35</td>\n",
       "      <td>2.76</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1.06</td>\n",
       "      <td>2.31</td>\n",
       "      <td>750.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>14.21</td>\n",
       "      <td>4.04</td>\n",
       "      <td>2.44</td>\n",
       "      <td>18.9</td>\n",
       "      <td>111.0</td>\n",
       "      <td>2.85</td>\n",
       "      <td>2.65</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.25</td>\n",
       "      <td>5.24</td>\n",
       "      <td>0.87</td>\n",
       "      <td>3.33</td>\n",
       "      <td>1080.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>11.76</td>\n",
       "      <td>2.68</td>\n",
       "      <td>2.92</td>\n",
       "      <td>20.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>1.75</td>\n",
       "      <td>2.03</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.80</td>\n",
       "      <td>1.23</td>\n",
       "      <td>2.50</td>\n",
       "      <td>607.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     alcohol  malic_acid   ash  alcalinity_of_ash  magnesium  total_phenols  \\\n",
       "160    12.36        3.83  2.38               21.0       88.0           2.30   \n",
       "156    13.84        4.12  2.38               19.5       89.0           1.80   \n",
       "78     12.33        0.99  1.95               14.8      136.0           1.90   \n",
       "45     14.21        4.04  2.44               18.9      111.0           2.85   \n",
       "112    11.76        2.68  2.92               20.0      103.0           1.75   \n",
       "\n",
       "     flavanoids  nonflavanoid_phenols  proanthocyanins  color_intensity   hue  \\\n",
       "160        0.92                  0.50             1.04             7.65  0.56   \n",
       "156        0.83                  0.48             1.56             9.01  0.57   \n",
       "78         1.85                  0.35             2.76             3.40  1.06   \n",
       "45         2.65                  0.30             1.25             5.24  0.87   \n",
       "112        2.03                  0.60             1.05             3.80  1.23   \n",
       "\n",
       "     od280/od315_of_diluted_wines  proline  \n",
       "160                          1.58    520.0  \n",
       "156                          1.64    480.0  \n",
       "78                           2.31    750.0  \n",
       "45                           3.33   1080.0  \n",
       "112                          2.50    607.0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(x_test.shape)\n",
    "print(x_test.size)\n",
    "x_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "57de6606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(142,)\n",
      "142\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "81     1\n",
       "6      0\n",
       "61     1\n",
       "126    1\n",
       "41     0\n",
       "dtype: int32"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(y_train.shape)\n",
    "print(y_train.size)\n",
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "84de42e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36,)\n",
      "36\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "160    2\n",
       "156    2\n",
       "78     1\n",
       "45     0\n",
       "112    1\n",
       "dtype: int32"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(y_test.shape)\n",
    "print(y_test.size)\n",
    "y_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4b97ff20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier()"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "lgm=LGBMClassifier()\n",
    "clf=lgm.fit(x_train,y_train)\n",
    "clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0c8dd2f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b8d2d898",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 1, 0, 1, 2, 0, 2, 1, 2, 2, 2, 1, 1, 2, 0, 0, 0, 0, 2, 0, 0,\n",
       "       1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 2, 0, 2])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred=clf.predict(x_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b71db63c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        14\n",
      "           1       1.00      1.00      1.00        11\n",
      "           2       1.00      1.00      1.00        11\n",
      "\n",
      "    accuracy                           1.00        36\n",
      "   macro avg       1.00      1.00      1.00        36\n",
      "weighted avg       1.00      1.00      1.00        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(metrics.classification_report(y_pred,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "abae7351",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[14,  0,  0],\n",
       "       [ 0, 11,  0],\n",
       "       [ 0,  0, 11]], dtype=int64)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(y_pred,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c230333a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sn\n",
    "cm=metrics.confusion_matrix(y_pred,y_test)\n",
    "sn.heatmap(cm,annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d58845c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fc7a5a5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.precision_score(y_test,y_pred,average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f9ed4a44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.recall_score(y_test,y_pred,average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e6914d56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.f1_score(y_test,y_pred,average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1803e38a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.mean_absolute_error(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "da5d7b3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.mean_squared_error(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8cd1d994",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.r2_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b4124c76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#root mean square error\n",
    "import math\n",
    "import numpy as np\n",
    "MSE=metrics.mean_squared_error(y_test,y_pred)\n",
    "RMSE=math.sqrt(MSE)\n",
    "RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ba5e44ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted_R2: 1.0\n"
     ]
    }
   ],
   "source": [
    "#Adjusted R2 score\n",
    "import numpy as np\n",
    "r2_score=metrics.r2_score(y_test,y_pred)\n",
    "n=y_test.shape[0]\n",
    "p=3\n",
    "x=(1-r2_score)\n",
    "y=(n-1)/(n-p-1)\n",
    "adj_r2=(1-(x*y))\n",
    "print('Adjusted_R2:',adj_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8e060751",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.93333333, 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 0.92857143, 1.        , 1.        ])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "score=cross_val_score(clf,x_train,y_train,cv=10,scoring='accuracy')\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "44caf51c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9861904761904763"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4f13455b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.055279130898786465"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score.std()*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "db225b34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=LGBMClassifier(), n_jobs=-1,\n",
       "             param_grid={'learning_rate': [0.01, 0.1], 'max_depth': [5, 10, 15],\n",
       "                         'n_estimators': [100, 500, 1000],\n",
       "                         'num_leaves': [20, 30, 40]},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "params = {'max_depth': [5, 10, 15],'learning_rate': [0.01, 0.1],'n_estimators': [100, 500, 1000],\n",
    "          'num_leaves': [20, 30, 40]}\n",
    "lgbm_hpt=GridSearchCV(clf,params,cv=5,scoring='accuracy',n_jobs=-1)\n",
    "lgbm_hpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fdc30fb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=LGBMClassifier(), n_jobs=-1,\n",
       "             param_grid={'learning_rate': [0.01, 0.1], 'max_depth': [5, 10, 15],\n",
       "                         'n_estimators': [100, 500, 1000],\n",
       "                         'num_leaves': [20, 30, 40]},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm_hpt.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c5728afe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(learning_rate=0.01, max_depth=5, n_estimators=1000,\n",
       "               num_leaves=20)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm_hpt.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "31f6be6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm_hpt.best_index_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e2181f44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 1000, 'num_leaves': 20}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm_hpt.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "54b11858",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9785714285714286"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm_hpt.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4fb36959",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.04288764, 0.04352388, 0.04600658, 0.19462004, 0.19082022,\n",
       "        0.20022049, 0.54045105, 0.54805946, 0.57916117, 0.03720436,\n",
       "        0.04020276, 0.03760438, 0.19111843, 0.19052219, 0.19832377,\n",
       "        0.53292575, 0.54094467, 0.57526541, 0.04040384, 0.03830228,\n",
       "        0.04140449, 0.19941974, 0.19342403, 0.21242485, 0.53154712,\n",
       "        0.52314906, 0.54545817, 0.04270501, 0.04240518, 0.04370236,\n",
       "        0.09421525, 0.08681393, 0.09301   , 0.13241286, 0.13231382,\n",
       "        0.13561487, 0.04500337, 0.05040717, 0.0458096 , 0.09156704,\n",
       "        0.09138203, 0.09331069, 0.14341726, 0.12631807, 0.13571873,\n",
       "        0.04550362, 0.04270616, 0.04440341, 0.08460875, 0.08360848,\n",
       "        0.08880801, 0.12493191, 0.11946507, 0.12032781]),\n",
       " 'std_fit_time': array([0.00230532, 0.00342378, 0.00370918, 0.00816337, 0.01231889,\n",
       "        0.00688307, 0.02416738, 0.01444779, 0.01213665, 0.00092421,\n",
       "        0.00257833, 0.00183233, 0.00779947, 0.00405097, 0.007667  ,\n",
       "        0.01394031, 0.01977995, 0.02191991, 0.00278342, 0.00074922,\n",
       "        0.00381323, 0.00791491, 0.00773568, 0.00683556, 0.0095297 ,\n",
       "        0.01405178, 0.01079781, 0.00150167, 0.00146391, 0.00107438,\n",
       "        0.01089501, 0.01103751, 0.01964484, 0.0367246 , 0.03298951,\n",
       "        0.03301762, 0.0020773 , 0.00895604, 0.00540247, 0.01402756,\n",
       "        0.01513436, 0.01982196, 0.03446836, 0.03369232, 0.03482169,\n",
       "        0.00170466, 0.00102749, 0.0018304 , 0.01227429, 0.01361093,\n",
       "        0.01604345, 0.03107249, 0.03441972, 0.03456167]),\n",
       " 'mean_score_time': array([0.00202241, 0.00220804, 0.00159993, 0.00320015, 0.00260015,\n",
       "        0.00300007, 0.00560145, 0.00570168, 0.00590148, 0.00180006,\n",
       "        0.00140066, 0.00159993, 0.00300035, 0.00340033, 0.00280004,\n",
       "        0.00519958, 0.00519972, 0.0052    , 0.00140057, 0.00160022,\n",
       "        0.0018002 , 0.0032001 , 0.0032002 , 0.00310106, 0.00570297,\n",
       "        0.00570126, 0.0058001 , 0.00180001, 0.00179977, 0.00180049,\n",
       "        0.00200114, 0.00220051, 0.00180011, 0.00160017, 0.00220113,\n",
       "        0.00190101, 0.00339985, 0.00140133, 0.00160108, 0.00200028,\n",
       "        0.0018002 , 0.00180044, 0.00240192, 0.00220013, 0.00200033,\n",
       "        0.00139995, 0.00180016, 0.00140004, 0.00200009, 0.00200009,\n",
       "        0.00200019, 0.00241265, 0.00181098, 0.00180387]),\n",
       " 'std_score_time': array([4.40362665e-05, 7.48532607e-04, 4.89901498e-04, 4.00137969e-04,\n",
       "        4.89940386e-04, 1.78416128e-07, 8.00458861e-04, 1.16601739e-03,\n",
       "        6.62168511e-04, 4.00066404e-04, 4.89726884e-04, 4.89706900e-04,\n",
       "        6.67572021e-07, 4.90368956e-04, 3.99971037e-04, 4.00236120e-04,\n",
       "        4.00162453e-04, 9.79598382e-04, 4.90778089e-04, 4.89843011e-04,\n",
       "        3.99661103e-04, 3.99923509e-04, 3.99875840e-04, 2.02441293e-04,\n",
       "        8.69929981e-04, 7.48093668e-04, 7.49247940e-04, 3.99923339e-04,\n",
       "        4.01115503e-04, 4.00164215e-04, 1.43527193e-06, 9.79540039e-04,\n",
       "        4.00090257e-04, 8.00263908e-04, 4.00283803e-04, 6.62878235e-04,\n",
       "        1.95930863e-03, 4.91421689e-04, 7.99228774e-04, 4.10190833e-07,\n",
       "        4.00257253e-04, 3.99900375e-04, 4.88450875e-04, 4.00185624e-04,\n",
       "        6.32258921e-04, 4.89726234e-04, 3.99875726e-04, 4.90037671e-04,\n",
       "        2.13248060e-07, 2.13248060e-07, 2.43140197e-07, 8.75524180e-04,\n",
       "        7.51558797e-04, 4.02032999e-04]),\n",
       " 'param_learning_rate': masked_array(data=[0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
       "                    0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
       "                    0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
       "                    0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
       "                    0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
       "                    0.1, 0.1, 0.1, 0.1, 0.1],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_max_depth': masked_array(data=[5, 5, 5, 5, 5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 15, 15, 15, 15, 15, 15, 15, 15, 15, 5, 5, 5, 5,\n",
       "                    5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 10, 10, 10, 10, 15,\n",
       "                    15, 15, 15, 15, 15, 15, 15, 15],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_n_estimators': masked_array(data=[100, 100, 100, 500, 500, 500, 1000, 1000, 1000, 100,\n",
       "                    100, 100, 500, 500, 500, 1000, 1000, 1000, 100, 100,\n",
       "                    100, 500, 500, 500, 1000, 1000, 1000, 100, 100, 100,\n",
       "                    500, 500, 500, 1000, 1000, 1000, 100, 100, 100, 500,\n",
       "                    500, 500, 1000, 1000, 1000, 100, 100, 100, 500, 500,\n",
       "                    500, 1000, 1000, 1000],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_num_leaves': masked_array(data=[20, 30, 40, 20, 30, 40, 20, 30, 40, 20, 30, 40, 20, 30,\n",
       "                    40, 20, 30, 40, 20, 30, 40, 20, 30, 40, 20, 30, 40, 20,\n",
       "                    30, 40, 20, 30, 40, 20, 30, 40, 20, 30, 40, 20, 30, 40,\n",
       "                    20, 30, 40, 20, 30, 40, 20, 30, 40, 20, 30, 40],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'learning_rate': 0.01,\n",
       "   'max_depth': 5,\n",
       "   'n_estimators': 100,\n",
       "   'num_leaves': 20},\n",
       "  {'learning_rate': 0.01,\n",
       "   'max_depth': 5,\n",
       "   'n_estimators': 100,\n",
       "   'num_leaves': 30},\n",
       "  {'learning_rate': 0.01,\n",
       "   'max_depth': 5,\n",
       "   'n_estimators': 100,\n",
       "   'num_leaves': 40},\n",
       "  {'learning_rate': 0.01,\n",
       "   'max_depth': 5,\n",
       "   'n_estimators': 500,\n",
       "   'num_leaves': 20},\n",
       "  {'learning_rate': 0.01,\n",
       "   'max_depth': 5,\n",
       "   'n_estimators': 500,\n",
       "   'num_leaves': 30},\n",
       "  {'learning_rate': 0.01,\n",
       "   'max_depth': 5,\n",
       "   'n_estimators': 500,\n",
       "   'num_leaves': 40},\n",
       "  {'learning_rate': 0.01,\n",
       "   'max_depth': 5,\n",
       "   'n_estimators': 1000,\n",
       "   'num_leaves': 20},\n",
       "  {'learning_rate': 0.01,\n",
       "   'max_depth': 5,\n",
       "   'n_estimators': 1000,\n",
       "   'num_leaves': 30},\n",
       "  {'learning_rate': 0.01,\n",
       "   'max_depth': 5,\n",
       "   'n_estimators': 1000,\n",
       "   'num_leaves': 40},\n",
       "  {'learning_rate': 0.01,\n",
       "   'max_depth': 10,\n",
       "   'n_estimators': 100,\n",
       "   'num_leaves': 20},\n",
       "  {'learning_rate': 0.01,\n",
       "   'max_depth': 10,\n",
       "   'n_estimators': 100,\n",
       "   'num_leaves': 30},\n",
       "  {'learning_rate': 0.01,\n",
       "   'max_depth': 10,\n",
       "   'n_estimators': 100,\n",
       "   'num_leaves': 40},\n",
       "  {'learning_rate': 0.01,\n",
       "   'max_depth': 10,\n",
       "   'n_estimators': 500,\n",
       "   'num_leaves': 20},\n",
       "  {'learning_rate': 0.01,\n",
       "   'max_depth': 10,\n",
       "   'n_estimators': 500,\n",
       "   'num_leaves': 30},\n",
       "  {'learning_rate': 0.01,\n",
       "   'max_depth': 10,\n",
       "   'n_estimators': 500,\n",
       "   'num_leaves': 40},\n",
       "  {'learning_rate': 0.01,\n",
       "   'max_depth': 10,\n",
       "   'n_estimators': 1000,\n",
       "   'num_leaves': 20},\n",
       "  {'learning_rate': 0.01,\n",
       "   'max_depth': 10,\n",
       "   'n_estimators': 1000,\n",
       "   'num_leaves': 30},\n",
       "  {'learning_rate': 0.01,\n",
       "   'max_depth': 10,\n",
       "   'n_estimators': 1000,\n",
       "   'num_leaves': 40},\n",
       "  {'learning_rate': 0.01,\n",
       "   'max_depth': 15,\n",
       "   'n_estimators': 100,\n",
       "   'num_leaves': 20},\n",
       "  {'learning_rate': 0.01,\n",
       "   'max_depth': 15,\n",
       "   'n_estimators': 100,\n",
       "   'num_leaves': 30},\n",
       "  {'learning_rate': 0.01,\n",
       "   'max_depth': 15,\n",
       "   'n_estimators': 100,\n",
       "   'num_leaves': 40},\n",
       "  {'learning_rate': 0.01,\n",
       "   'max_depth': 15,\n",
       "   'n_estimators': 500,\n",
       "   'num_leaves': 20},\n",
       "  {'learning_rate': 0.01,\n",
       "   'max_depth': 15,\n",
       "   'n_estimators': 500,\n",
       "   'num_leaves': 30},\n",
       "  {'learning_rate': 0.01,\n",
       "   'max_depth': 15,\n",
       "   'n_estimators': 500,\n",
       "   'num_leaves': 40},\n",
       "  {'learning_rate': 0.01,\n",
       "   'max_depth': 15,\n",
       "   'n_estimators': 1000,\n",
       "   'num_leaves': 20},\n",
       "  {'learning_rate': 0.01,\n",
       "   'max_depth': 15,\n",
       "   'n_estimators': 1000,\n",
       "   'num_leaves': 30},\n",
       "  {'learning_rate': 0.01,\n",
       "   'max_depth': 15,\n",
       "   'n_estimators': 1000,\n",
       "   'num_leaves': 40},\n",
       "  {'learning_rate': 0.1,\n",
       "   'max_depth': 5,\n",
       "   'n_estimators': 100,\n",
       "   'num_leaves': 20},\n",
       "  {'learning_rate': 0.1,\n",
       "   'max_depth': 5,\n",
       "   'n_estimators': 100,\n",
       "   'num_leaves': 30},\n",
       "  {'learning_rate': 0.1,\n",
       "   'max_depth': 5,\n",
       "   'n_estimators': 100,\n",
       "   'num_leaves': 40},\n",
       "  {'learning_rate': 0.1,\n",
       "   'max_depth': 5,\n",
       "   'n_estimators': 500,\n",
       "   'num_leaves': 20},\n",
       "  {'learning_rate': 0.1,\n",
       "   'max_depth': 5,\n",
       "   'n_estimators': 500,\n",
       "   'num_leaves': 30},\n",
       "  {'learning_rate': 0.1,\n",
       "   'max_depth': 5,\n",
       "   'n_estimators': 500,\n",
       "   'num_leaves': 40},\n",
       "  {'learning_rate': 0.1,\n",
       "   'max_depth': 5,\n",
       "   'n_estimators': 1000,\n",
       "   'num_leaves': 20},\n",
       "  {'learning_rate': 0.1,\n",
       "   'max_depth': 5,\n",
       "   'n_estimators': 1000,\n",
       "   'num_leaves': 30},\n",
       "  {'learning_rate': 0.1,\n",
       "   'max_depth': 5,\n",
       "   'n_estimators': 1000,\n",
       "   'num_leaves': 40},\n",
       "  {'learning_rate': 0.1,\n",
       "   'max_depth': 10,\n",
       "   'n_estimators': 100,\n",
       "   'num_leaves': 20},\n",
       "  {'learning_rate': 0.1,\n",
       "   'max_depth': 10,\n",
       "   'n_estimators': 100,\n",
       "   'num_leaves': 30},\n",
       "  {'learning_rate': 0.1,\n",
       "   'max_depth': 10,\n",
       "   'n_estimators': 100,\n",
       "   'num_leaves': 40},\n",
       "  {'learning_rate': 0.1,\n",
       "   'max_depth': 10,\n",
       "   'n_estimators': 500,\n",
       "   'num_leaves': 20},\n",
       "  {'learning_rate': 0.1,\n",
       "   'max_depth': 10,\n",
       "   'n_estimators': 500,\n",
       "   'num_leaves': 30},\n",
       "  {'learning_rate': 0.1,\n",
       "   'max_depth': 10,\n",
       "   'n_estimators': 500,\n",
       "   'num_leaves': 40},\n",
       "  {'learning_rate': 0.1,\n",
       "   'max_depth': 10,\n",
       "   'n_estimators': 1000,\n",
       "   'num_leaves': 20},\n",
       "  {'learning_rate': 0.1,\n",
       "   'max_depth': 10,\n",
       "   'n_estimators': 1000,\n",
       "   'num_leaves': 30},\n",
       "  {'learning_rate': 0.1,\n",
       "   'max_depth': 10,\n",
       "   'n_estimators': 1000,\n",
       "   'num_leaves': 40},\n",
       "  {'learning_rate': 0.1,\n",
       "   'max_depth': 15,\n",
       "   'n_estimators': 100,\n",
       "   'num_leaves': 20},\n",
       "  {'learning_rate': 0.1,\n",
       "   'max_depth': 15,\n",
       "   'n_estimators': 100,\n",
       "   'num_leaves': 30},\n",
       "  {'learning_rate': 0.1,\n",
       "   'max_depth': 15,\n",
       "   'n_estimators': 100,\n",
       "   'num_leaves': 40},\n",
       "  {'learning_rate': 0.1,\n",
       "   'max_depth': 15,\n",
       "   'n_estimators': 500,\n",
       "   'num_leaves': 20},\n",
       "  {'learning_rate': 0.1,\n",
       "   'max_depth': 15,\n",
       "   'n_estimators': 500,\n",
       "   'num_leaves': 30},\n",
       "  {'learning_rate': 0.1,\n",
       "   'max_depth': 15,\n",
       "   'n_estimators': 500,\n",
       "   'num_leaves': 40},\n",
       "  {'learning_rate': 0.1,\n",
       "   'max_depth': 15,\n",
       "   'n_estimators': 1000,\n",
       "   'num_leaves': 20},\n",
       "  {'learning_rate': 0.1,\n",
       "   'max_depth': 15,\n",
       "   'n_estimators': 1000,\n",
       "   'num_leaves': 30},\n",
       "  {'learning_rate': 0.1,\n",
       "   'max_depth': 15,\n",
       "   'n_estimators': 1000,\n",
       "   'num_leaves': 40}],\n",
       " 'split0_test_score': array([0.93103448, 0.93103448, 0.93103448, 0.96551724, 0.96551724,\n",
       "        0.96551724, 1.        , 1.        , 1.        , 0.93103448,\n",
       "        0.93103448, 0.93103448, 0.96551724, 0.96551724, 0.96551724,\n",
       "        1.        , 1.        , 1.        , 0.93103448, 0.93103448,\n",
       "        0.93103448, 0.96551724, 0.96551724, 0.96551724, 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        ]),\n",
       " 'split1_test_score': array([0.96551724, 0.96551724, 0.96551724, 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 0.96551724,\n",
       "        0.96551724, 0.96551724, 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 0.96551724, 0.96551724,\n",
       "        0.96551724, 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        ]),\n",
       " 'split2_test_score': array([0.92857143, 0.92857143, 0.92857143, 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 0.92857143,\n",
       "        0.92857143, 0.92857143, 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 0.92857143, 0.92857143,\n",
       "        0.92857143, 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        ]),\n",
       " 'split3_test_score': array([0.85714286, 0.85714286, 0.85714286, 0.89285714, 0.89285714,\n",
       "        0.89285714, 0.92857143, 0.92857143, 0.92857143, 0.85714286,\n",
       "        0.85714286, 0.85714286, 0.89285714, 0.89285714, 0.89285714,\n",
       "        0.92857143, 0.92857143, 0.92857143, 0.85714286, 0.85714286,\n",
       "        0.85714286, 0.89285714, 0.89285714, 0.89285714, 0.92857143,\n",
       "        0.92857143, 0.92857143, 0.92857143, 0.92857143, 0.92857143,\n",
       "        0.92857143, 0.92857143, 0.92857143, 0.92857143, 0.92857143,\n",
       "        0.92857143, 0.92857143, 0.92857143, 0.92857143, 0.92857143,\n",
       "        0.92857143, 0.92857143, 0.92857143, 0.92857143, 0.92857143,\n",
       "        0.92857143, 0.92857143, 0.92857143, 0.92857143, 0.92857143,\n",
       "        0.92857143, 0.92857143, 0.92857143, 0.92857143]),\n",
       " 'split4_test_score': array([0.92857143, 0.92857143, 0.92857143, 0.96428571, 0.96428571,\n",
       "        0.96428571, 0.96428571, 0.96428571, 0.96428571, 0.92857143,\n",
       "        0.92857143, 0.92857143, 0.96428571, 0.96428571, 0.96428571,\n",
       "        0.96428571, 0.96428571, 0.96428571, 0.92857143, 0.92857143,\n",
       "        0.92857143, 0.96428571, 0.96428571, 0.96428571, 0.96428571,\n",
       "        0.96428571, 0.96428571, 0.96428571, 0.96428571, 0.96428571,\n",
       "        0.96428571, 0.96428571, 0.96428571, 0.96428571, 0.96428571,\n",
       "        0.96428571, 0.96428571, 0.96428571, 0.96428571, 0.96428571,\n",
       "        0.96428571, 0.96428571, 0.96428571, 0.96428571, 0.96428571,\n",
       "        0.96428571, 0.96428571, 0.96428571, 0.96428571, 0.96428571,\n",
       "        0.96428571, 0.96428571, 0.96428571, 0.96428571]),\n",
       " 'mean_test_score': array([0.92216749, 0.92216749, 0.92216749, 0.96453202, 0.96453202,\n",
       "        0.96453202, 0.97857143, 0.97857143, 0.97857143, 0.92216749,\n",
       "        0.92216749, 0.92216749, 0.96453202, 0.96453202, 0.96453202,\n",
       "        0.97857143, 0.97857143, 0.97857143, 0.92216749, 0.92216749,\n",
       "        0.92216749, 0.96453202, 0.96453202, 0.96453202, 0.97857143,\n",
       "        0.97857143, 0.97857143, 0.97857143, 0.97857143, 0.97857143,\n",
       "        0.97857143, 0.97857143, 0.97857143, 0.97857143, 0.97857143,\n",
       "        0.97857143, 0.97857143, 0.97857143, 0.97857143, 0.97857143,\n",
       "        0.97857143, 0.97857143, 0.97857143, 0.97857143, 0.97857143,\n",
       "        0.97857143, 0.97857143, 0.97857143, 0.97857143, 0.97857143,\n",
       "        0.97857143, 0.97857143, 0.97857143, 0.97857143]),\n",
       " 'std_test_score': array([0.03540635, 0.03540635, 0.03540635, 0.03912614, 0.03912614,\n",
       "        0.03912614, 0.02857143, 0.02857143, 0.02857143, 0.03540635,\n",
       "        0.03540635, 0.03540635, 0.03912614, 0.03912614, 0.03912614,\n",
       "        0.02857143, 0.02857143, 0.02857143, 0.03540635, 0.03540635,\n",
       "        0.03540635, 0.03912614, 0.03912614, 0.03912614, 0.02857143,\n",
       "        0.02857143, 0.02857143, 0.02857143, 0.02857143, 0.02857143,\n",
       "        0.02857143, 0.02857143, 0.02857143, 0.02857143, 0.02857143,\n",
       "        0.02857143, 0.02857143, 0.02857143, 0.02857143, 0.02857143,\n",
       "        0.02857143, 0.02857143, 0.02857143, 0.02857143, 0.02857143,\n",
       "        0.02857143, 0.02857143, 0.02857143, 0.02857143, 0.02857143,\n",
       "        0.02857143, 0.02857143, 0.02857143, 0.02857143]),\n",
       " 'rank_test_score': array([46, 46, 46, 37, 37, 37,  1,  1,  1, 46, 46, 46, 37, 37, 37,  1,  1,\n",
       "         1, 46, 46, 46, 37, 37, 37,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1,  1,  1])}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm_hpt.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "76c71d4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_num_leaves</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.042888</td>\n",
       "      <td>0.002305</td>\n",
       "      <td>0.002022</td>\n",
       "      <td>4.403627e-05</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>20</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 5, 'n_est...</td>\n",
       "      <td>0.931034</td>\n",
       "      <td>0.965517</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.922167</td>\n",
       "      <td>0.035406</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.043524</td>\n",
       "      <td>0.003424</td>\n",
       "      <td>0.002208</td>\n",
       "      <td>7.485326e-04</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>30</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 5, 'n_est...</td>\n",
       "      <td>0.931034</td>\n",
       "      <td>0.965517</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.922167</td>\n",
       "      <td>0.035406</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.046007</td>\n",
       "      <td>0.003709</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>4.899015e-04</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>40</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 5, 'n_est...</td>\n",
       "      <td>0.931034</td>\n",
       "      <td>0.965517</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.922167</td>\n",
       "      <td>0.035406</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.194620</td>\n",
       "      <td>0.008163</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>4.001380e-04</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5</td>\n",
       "      <td>500</td>\n",
       "      <td>20</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 5, 'n_est...</td>\n",
       "      <td>0.965517</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>0.964286</td>\n",
       "      <td>0.964532</td>\n",
       "      <td>0.039126</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.190820</td>\n",
       "      <td>0.012319</td>\n",
       "      <td>0.002600</td>\n",
       "      <td>4.899404e-04</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5</td>\n",
       "      <td>500</td>\n",
       "      <td>30</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 5, 'n_est...</td>\n",
       "      <td>0.965517</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>0.964286</td>\n",
       "      <td>0.964532</td>\n",
       "      <td>0.039126</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.200220</td>\n",
       "      <td>0.006883</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>1.784161e-07</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5</td>\n",
       "      <td>500</td>\n",
       "      <td>40</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 5, 'n_est...</td>\n",
       "      <td>0.965517</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>0.964286</td>\n",
       "      <td>0.964532</td>\n",
       "      <td>0.039126</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.540451</td>\n",
       "      <td>0.024167</td>\n",
       "      <td>0.005601</td>\n",
       "      <td>8.004589e-04</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5</td>\n",
       "      <td>1000</td>\n",
       "      <td>20</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 5, 'n_est...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.964286</td>\n",
       "      <td>0.978571</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.548059</td>\n",
       "      <td>0.014448</td>\n",
       "      <td>0.005702</td>\n",
       "      <td>1.166017e-03</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5</td>\n",
       "      <td>1000</td>\n",
       "      <td>30</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 5, 'n_est...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.964286</td>\n",
       "      <td>0.978571</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.579161</td>\n",
       "      <td>0.012137</td>\n",
       "      <td>0.005901</td>\n",
       "      <td>6.621685e-04</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5</td>\n",
       "      <td>1000</td>\n",
       "      <td>40</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 5, 'n_est...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.964286</td>\n",
       "      <td>0.978571</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.037204</td>\n",
       "      <td>0.000924</td>\n",
       "      <td>0.001800</td>\n",
       "      <td>4.000664e-04</td>\n",
       "      <td>0.01</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>20</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 10, 'n_es...</td>\n",
       "      <td>0.931034</td>\n",
       "      <td>0.965517</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.922167</td>\n",
       "      <td>0.035406</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.040203</td>\n",
       "      <td>0.002578</td>\n",
       "      <td>0.001401</td>\n",
       "      <td>4.897269e-04</td>\n",
       "      <td>0.01</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>30</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 10, 'n_es...</td>\n",
       "      <td>0.931034</td>\n",
       "      <td>0.965517</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.922167</td>\n",
       "      <td>0.035406</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.037604</td>\n",
       "      <td>0.001832</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>4.897069e-04</td>\n",
       "      <td>0.01</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>40</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 10, 'n_es...</td>\n",
       "      <td>0.931034</td>\n",
       "      <td>0.965517</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.922167</td>\n",
       "      <td>0.035406</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.191118</td>\n",
       "      <td>0.007799</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>6.675720e-07</td>\n",
       "      <td>0.01</td>\n",
       "      <td>10</td>\n",
       "      <td>500</td>\n",
       "      <td>20</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 10, 'n_es...</td>\n",
       "      <td>0.965517</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>0.964286</td>\n",
       "      <td>0.964532</td>\n",
       "      <td>0.039126</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.190522</td>\n",
       "      <td>0.004051</td>\n",
       "      <td>0.003400</td>\n",
       "      <td>4.903690e-04</td>\n",
       "      <td>0.01</td>\n",
       "      <td>10</td>\n",
       "      <td>500</td>\n",
       "      <td>30</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 10, 'n_es...</td>\n",
       "      <td>0.965517</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>0.964286</td>\n",
       "      <td>0.964532</td>\n",
       "      <td>0.039126</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.198324</td>\n",
       "      <td>0.007667</td>\n",
       "      <td>0.002800</td>\n",
       "      <td>3.999710e-04</td>\n",
       "      <td>0.01</td>\n",
       "      <td>10</td>\n",
       "      <td>500</td>\n",
       "      <td>40</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 10, 'n_es...</td>\n",
       "      <td>0.965517</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>0.964286</td>\n",
       "      <td>0.964532</td>\n",
       "      <td>0.039126</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.532926</td>\n",
       "      <td>0.013940</td>\n",
       "      <td>0.005200</td>\n",
       "      <td>4.002361e-04</td>\n",
       "      <td>0.01</td>\n",
       "      <td>10</td>\n",
       "      <td>1000</td>\n",
       "      <td>20</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 10, 'n_es...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.964286</td>\n",
       "      <td>0.978571</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.540945</td>\n",
       "      <td>0.019780</td>\n",
       "      <td>0.005200</td>\n",
       "      <td>4.001625e-04</td>\n",
       "      <td>0.01</td>\n",
       "      <td>10</td>\n",
       "      <td>1000</td>\n",
       "      <td>30</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 10, 'n_es...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.964286</td>\n",
       "      <td>0.978571</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.575265</td>\n",
       "      <td>0.021920</td>\n",
       "      <td>0.005200</td>\n",
       "      <td>9.795984e-04</td>\n",
       "      <td>0.01</td>\n",
       "      <td>10</td>\n",
       "      <td>1000</td>\n",
       "      <td>40</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 10, 'n_es...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.964286</td>\n",
       "      <td>0.978571</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.040404</td>\n",
       "      <td>0.002783</td>\n",
       "      <td>0.001401</td>\n",
       "      <td>4.907781e-04</td>\n",
       "      <td>0.01</td>\n",
       "      <td>15</td>\n",
       "      <td>100</td>\n",
       "      <td>20</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 15, 'n_es...</td>\n",
       "      <td>0.931034</td>\n",
       "      <td>0.965517</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.922167</td>\n",
       "      <td>0.035406</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.038302</td>\n",
       "      <td>0.000749</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>4.898430e-04</td>\n",
       "      <td>0.01</td>\n",
       "      <td>15</td>\n",
       "      <td>100</td>\n",
       "      <td>30</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 15, 'n_es...</td>\n",
       "      <td>0.931034</td>\n",
       "      <td>0.965517</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.922167</td>\n",
       "      <td>0.035406</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.041404</td>\n",
       "      <td>0.003813</td>\n",
       "      <td>0.001800</td>\n",
       "      <td>3.996611e-04</td>\n",
       "      <td>0.01</td>\n",
       "      <td>15</td>\n",
       "      <td>100</td>\n",
       "      <td>40</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 15, 'n_es...</td>\n",
       "      <td>0.931034</td>\n",
       "      <td>0.965517</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.922167</td>\n",
       "      <td>0.035406</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.199420</td>\n",
       "      <td>0.007915</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>3.999235e-04</td>\n",
       "      <td>0.01</td>\n",
       "      <td>15</td>\n",
       "      <td>500</td>\n",
       "      <td>20</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 15, 'n_es...</td>\n",
       "      <td>0.965517</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>0.964286</td>\n",
       "      <td>0.964532</td>\n",
       "      <td>0.039126</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.193424</td>\n",
       "      <td>0.007736</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>3.998758e-04</td>\n",
       "      <td>0.01</td>\n",
       "      <td>15</td>\n",
       "      <td>500</td>\n",
       "      <td>30</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 15, 'n_es...</td>\n",
       "      <td>0.965517</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>0.964286</td>\n",
       "      <td>0.964532</td>\n",
       "      <td>0.039126</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.212425</td>\n",
       "      <td>0.006836</td>\n",
       "      <td>0.003101</td>\n",
       "      <td>2.024413e-04</td>\n",
       "      <td>0.01</td>\n",
       "      <td>15</td>\n",
       "      <td>500</td>\n",
       "      <td>40</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 15, 'n_es...</td>\n",
       "      <td>0.965517</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>0.964286</td>\n",
       "      <td>0.964532</td>\n",
       "      <td>0.039126</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.531547</td>\n",
       "      <td>0.009530</td>\n",
       "      <td>0.005703</td>\n",
       "      <td>8.699300e-04</td>\n",
       "      <td>0.01</td>\n",
       "      <td>15</td>\n",
       "      <td>1000</td>\n",
       "      <td>20</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 15, 'n_es...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.964286</td>\n",
       "      <td>0.978571</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.523149</td>\n",
       "      <td>0.014052</td>\n",
       "      <td>0.005701</td>\n",
       "      <td>7.480937e-04</td>\n",
       "      <td>0.01</td>\n",
       "      <td>15</td>\n",
       "      <td>1000</td>\n",
       "      <td>30</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 15, 'n_es...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.964286</td>\n",
       "      <td>0.978571</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.545458</td>\n",
       "      <td>0.010798</td>\n",
       "      <td>0.005800</td>\n",
       "      <td>7.492479e-04</td>\n",
       "      <td>0.01</td>\n",
       "      <td>15</td>\n",
       "      <td>1000</td>\n",
       "      <td>40</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 15, 'n_es...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.964286</td>\n",
       "      <td>0.978571</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.042705</td>\n",
       "      <td>0.001502</td>\n",
       "      <td>0.001800</td>\n",
       "      <td>3.999233e-04</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>20</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 5, 'n_esti...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.964286</td>\n",
       "      <td>0.978571</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.042405</td>\n",
       "      <td>0.001464</td>\n",
       "      <td>0.001800</td>\n",
       "      <td>4.011155e-04</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>30</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 5, 'n_esti...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.964286</td>\n",
       "      <td>0.978571</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.043702</td>\n",
       "      <td>0.001074</td>\n",
       "      <td>0.001800</td>\n",
       "      <td>4.001642e-04</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>40</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 5, 'n_esti...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.964286</td>\n",
       "      <td>0.978571</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.094215</td>\n",
       "      <td>0.010895</td>\n",
       "      <td>0.002001</td>\n",
       "      <td>1.435272e-06</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>500</td>\n",
       "      <td>20</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 5, 'n_esti...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.964286</td>\n",
       "      <td>0.978571</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.086814</td>\n",
       "      <td>0.011038</td>\n",
       "      <td>0.002201</td>\n",
       "      <td>9.795400e-04</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>500</td>\n",
       "      <td>30</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 5, 'n_esti...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.964286</td>\n",
       "      <td>0.978571</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.093010</td>\n",
       "      <td>0.019645</td>\n",
       "      <td>0.001800</td>\n",
       "      <td>4.000903e-04</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>500</td>\n",
       "      <td>40</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 5, 'n_esti...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.964286</td>\n",
       "      <td>0.978571</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.132413</td>\n",
       "      <td>0.036725</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>8.002639e-04</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>1000</td>\n",
       "      <td>20</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 5, 'n_esti...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.964286</td>\n",
       "      <td>0.978571</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.132314</td>\n",
       "      <td>0.032990</td>\n",
       "      <td>0.002201</td>\n",
       "      <td>4.002838e-04</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>1000</td>\n",
       "      <td>30</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 5, 'n_esti...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.964286</td>\n",
       "      <td>0.978571</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.135615</td>\n",
       "      <td>0.033018</td>\n",
       "      <td>0.001901</td>\n",
       "      <td>6.628782e-04</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>1000</td>\n",
       "      <td>40</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 5, 'n_esti...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.964286</td>\n",
       "      <td>0.978571</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.045003</td>\n",
       "      <td>0.002077</td>\n",
       "      <td>0.003400</td>\n",
       "      <td>1.959309e-03</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>20</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 10, 'n_est...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.964286</td>\n",
       "      <td>0.978571</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.050407</td>\n",
       "      <td>0.008956</td>\n",
       "      <td>0.001401</td>\n",
       "      <td>4.914217e-04</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>30</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 10, 'n_est...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.964286</td>\n",
       "      <td>0.978571</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.045810</td>\n",
       "      <td>0.005402</td>\n",
       "      <td>0.001601</td>\n",
       "      <td>7.992288e-04</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>40</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 10, 'n_est...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.964286</td>\n",
       "      <td>0.978571</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.091567</td>\n",
       "      <td>0.014028</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>4.101908e-07</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10</td>\n",
       "      <td>500</td>\n",
       "      <td>20</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 10, 'n_est...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.964286</td>\n",
       "      <td>0.978571</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.091382</td>\n",
       "      <td>0.015134</td>\n",
       "      <td>0.001800</td>\n",
       "      <td>4.002573e-04</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10</td>\n",
       "      <td>500</td>\n",
       "      <td>30</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 10, 'n_est...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.964286</td>\n",
       "      <td>0.978571</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.093311</td>\n",
       "      <td>0.019822</td>\n",
       "      <td>0.001800</td>\n",
       "      <td>3.999004e-04</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10</td>\n",
       "      <td>500</td>\n",
       "      <td>40</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 10, 'n_est...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.964286</td>\n",
       "      <td>0.978571</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.143417</td>\n",
       "      <td>0.034468</td>\n",
       "      <td>0.002402</td>\n",
       "      <td>4.884509e-04</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10</td>\n",
       "      <td>1000</td>\n",
       "      <td>20</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 10, 'n_est...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.964286</td>\n",
       "      <td>0.978571</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.126318</td>\n",
       "      <td>0.033692</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>4.001856e-04</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10</td>\n",
       "      <td>1000</td>\n",
       "      <td>30</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 10, 'n_est...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.964286</td>\n",
       "      <td>0.978571</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.135719</td>\n",
       "      <td>0.034822</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>6.322589e-04</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10</td>\n",
       "      <td>1000</td>\n",
       "      <td>40</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 10, 'n_est...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.964286</td>\n",
       "      <td>0.978571</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.045504</td>\n",
       "      <td>0.001705</td>\n",
       "      <td>0.001400</td>\n",
       "      <td>4.897262e-04</td>\n",
       "      <td>0.1</td>\n",
       "      <td>15</td>\n",
       "      <td>100</td>\n",
       "      <td>20</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 15, 'n_est...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.964286</td>\n",
       "      <td>0.978571</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.042706</td>\n",
       "      <td>0.001027</td>\n",
       "      <td>0.001800</td>\n",
       "      <td>3.998757e-04</td>\n",
       "      <td>0.1</td>\n",
       "      <td>15</td>\n",
       "      <td>100</td>\n",
       "      <td>30</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 15, 'n_est...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.964286</td>\n",
       "      <td>0.978571</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.044403</td>\n",
       "      <td>0.001830</td>\n",
       "      <td>0.001400</td>\n",
       "      <td>4.900377e-04</td>\n",
       "      <td>0.1</td>\n",
       "      <td>15</td>\n",
       "      <td>100</td>\n",
       "      <td>40</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 15, 'n_est...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.964286</td>\n",
       "      <td>0.978571</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.084609</td>\n",
       "      <td>0.012274</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>2.132481e-07</td>\n",
       "      <td>0.1</td>\n",
       "      <td>15</td>\n",
       "      <td>500</td>\n",
       "      <td>20</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 15, 'n_est...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.964286</td>\n",
       "      <td>0.978571</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.083608</td>\n",
       "      <td>0.013611</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>2.132481e-07</td>\n",
       "      <td>0.1</td>\n",
       "      <td>15</td>\n",
       "      <td>500</td>\n",
       "      <td>30</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 15, 'n_est...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.964286</td>\n",
       "      <td>0.978571</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.088808</td>\n",
       "      <td>0.016043</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>2.431402e-07</td>\n",
       "      <td>0.1</td>\n",
       "      <td>15</td>\n",
       "      <td>500</td>\n",
       "      <td>40</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 15, 'n_est...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.964286</td>\n",
       "      <td>0.978571</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.124932</td>\n",
       "      <td>0.031072</td>\n",
       "      <td>0.002413</td>\n",
       "      <td>8.755242e-04</td>\n",
       "      <td>0.1</td>\n",
       "      <td>15</td>\n",
       "      <td>1000</td>\n",
       "      <td>20</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 15, 'n_est...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.964286</td>\n",
       "      <td>0.978571</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0.119465</td>\n",
       "      <td>0.034420</td>\n",
       "      <td>0.001811</td>\n",
       "      <td>7.515588e-04</td>\n",
       "      <td>0.1</td>\n",
       "      <td>15</td>\n",
       "      <td>1000</td>\n",
       "      <td>30</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 15, 'n_est...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.964286</td>\n",
       "      <td>0.978571</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0.120328</td>\n",
       "      <td>0.034562</td>\n",
       "      <td>0.001804</td>\n",
       "      <td>4.020330e-04</td>\n",
       "      <td>0.1</td>\n",
       "      <td>15</td>\n",
       "      <td>1000</td>\n",
       "      <td>40</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 15, 'n_est...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.964286</td>\n",
       "      <td>0.978571</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        0.042888      0.002305         0.002022    4.403627e-05   \n",
       "1        0.043524      0.003424         0.002208    7.485326e-04   \n",
       "2        0.046007      0.003709         0.001600    4.899015e-04   \n",
       "3        0.194620      0.008163         0.003200    4.001380e-04   \n",
       "4        0.190820      0.012319         0.002600    4.899404e-04   \n",
       "5        0.200220      0.006883         0.003000    1.784161e-07   \n",
       "6        0.540451      0.024167         0.005601    8.004589e-04   \n",
       "7        0.548059      0.014448         0.005702    1.166017e-03   \n",
       "8        0.579161      0.012137         0.005901    6.621685e-04   \n",
       "9        0.037204      0.000924         0.001800    4.000664e-04   \n",
       "10       0.040203      0.002578         0.001401    4.897269e-04   \n",
       "11       0.037604      0.001832         0.001600    4.897069e-04   \n",
       "12       0.191118      0.007799         0.003000    6.675720e-07   \n",
       "13       0.190522      0.004051         0.003400    4.903690e-04   \n",
       "14       0.198324      0.007667         0.002800    3.999710e-04   \n",
       "15       0.532926      0.013940         0.005200    4.002361e-04   \n",
       "16       0.540945      0.019780         0.005200    4.001625e-04   \n",
       "17       0.575265      0.021920         0.005200    9.795984e-04   \n",
       "18       0.040404      0.002783         0.001401    4.907781e-04   \n",
       "19       0.038302      0.000749         0.001600    4.898430e-04   \n",
       "20       0.041404      0.003813         0.001800    3.996611e-04   \n",
       "21       0.199420      0.007915         0.003200    3.999235e-04   \n",
       "22       0.193424      0.007736         0.003200    3.998758e-04   \n",
       "23       0.212425      0.006836         0.003101    2.024413e-04   \n",
       "24       0.531547      0.009530         0.005703    8.699300e-04   \n",
       "25       0.523149      0.014052         0.005701    7.480937e-04   \n",
       "26       0.545458      0.010798         0.005800    7.492479e-04   \n",
       "27       0.042705      0.001502         0.001800    3.999233e-04   \n",
       "28       0.042405      0.001464         0.001800    4.011155e-04   \n",
       "29       0.043702      0.001074         0.001800    4.001642e-04   \n",
       "30       0.094215      0.010895         0.002001    1.435272e-06   \n",
       "31       0.086814      0.011038         0.002201    9.795400e-04   \n",
       "32       0.093010      0.019645         0.001800    4.000903e-04   \n",
       "33       0.132413      0.036725         0.001600    8.002639e-04   \n",
       "34       0.132314      0.032990         0.002201    4.002838e-04   \n",
       "35       0.135615      0.033018         0.001901    6.628782e-04   \n",
       "36       0.045003      0.002077         0.003400    1.959309e-03   \n",
       "37       0.050407      0.008956         0.001401    4.914217e-04   \n",
       "38       0.045810      0.005402         0.001601    7.992288e-04   \n",
       "39       0.091567      0.014028         0.002000    4.101908e-07   \n",
       "40       0.091382      0.015134         0.001800    4.002573e-04   \n",
       "41       0.093311      0.019822         0.001800    3.999004e-04   \n",
       "42       0.143417      0.034468         0.002402    4.884509e-04   \n",
       "43       0.126318      0.033692         0.002200    4.001856e-04   \n",
       "44       0.135719      0.034822         0.002000    6.322589e-04   \n",
       "45       0.045504      0.001705         0.001400    4.897262e-04   \n",
       "46       0.042706      0.001027         0.001800    3.998757e-04   \n",
       "47       0.044403      0.001830         0.001400    4.900377e-04   \n",
       "48       0.084609      0.012274         0.002000    2.132481e-07   \n",
       "49       0.083608      0.013611         0.002000    2.132481e-07   \n",
       "50       0.088808      0.016043         0.002000    2.431402e-07   \n",
       "51       0.124932      0.031072         0.002413    8.755242e-04   \n",
       "52       0.119465      0.034420         0.001811    7.515588e-04   \n",
       "53       0.120328      0.034562         0.001804    4.020330e-04   \n",
       "\n",
       "   param_learning_rate param_max_depth param_n_estimators param_num_leaves  \\\n",
       "0                 0.01               5                100               20   \n",
       "1                 0.01               5                100               30   \n",
       "2                 0.01               5                100               40   \n",
       "3                 0.01               5                500               20   \n",
       "4                 0.01               5                500               30   \n",
       "5                 0.01               5                500               40   \n",
       "6                 0.01               5               1000               20   \n",
       "7                 0.01               5               1000               30   \n",
       "8                 0.01               5               1000               40   \n",
       "9                 0.01              10                100               20   \n",
       "10                0.01              10                100               30   \n",
       "11                0.01              10                100               40   \n",
       "12                0.01              10                500               20   \n",
       "13                0.01              10                500               30   \n",
       "14                0.01              10                500               40   \n",
       "15                0.01              10               1000               20   \n",
       "16                0.01              10               1000               30   \n",
       "17                0.01              10               1000               40   \n",
       "18                0.01              15                100               20   \n",
       "19                0.01              15                100               30   \n",
       "20                0.01              15                100               40   \n",
       "21                0.01              15                500               20   \n",
       "22                0.01              15                500               30   \n",
       "23                0.01              15                500               40   \n",
       "24                0.01              15               1000               20   \n",
       "25                0.01              15               1000               30   \n",
       "26                0.01              15               1000               40   \n",
       "27                 0.1               5                100               20   \n",
       "28                 0.1               5                100               30   \n",
       "29                 0.1               5                100               40   \n",
       "30                 0.1               5                500               20   \n",
       "31                 0.1               5                500               30   \n",
       "32                 0.1               5                500               40   \n",
       "33                 0.1               5               1000               20   \n",
       "34                 0.1               5               1000               30   \n",
       "35                 0.1               5               1000               40   \n",
       "36                 0.1              10                100               20   \n",
       "37                 0.1              10                100               30   \n",
       "38                 0.1              10                100               40   \n",
       "39                 0.1              10                500               20   \n",
       "40                 0.1              10                500               30   \n",
       "41                 0.1              10                500               40   \n",
       "42                 0.1              10               1000               20   \n",
       "43                 0.1              10               1000               30   \n",
       "44                 0.1              10               1000               40   \n",
       "45                 0.1              15                100               20   \n",
       "46                 0.1              15                100               30   \n",
       "47                 0.1              15                100               40   \n",
       "48                 0.1              15                500               20   \n",
       "49                 0.1              15                500               30   \n",
       "50                 0.1              15                500               40   \n",
       "51                 0.1              15               1000               20   \n",
       "52                 0.1              15               1000               30   \n",
       "53                 0.1              15               1000               40   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "0   {'learning_rate': 0.01, 'max_depth': 5, 'n_est...           0.931034   \n",
       "1   {'learning_rate': 0.01, 'max_depth': 5, 'n_est...           0.931034   \n",
       "2   {'learning_rate': 0.01, 'max_depth': 5, 'n_est...           0.931034   \n",
       "3   {'learning_rate': 0.01, 'max_depth': 5, 'n_est...           0.965517   \n",
       "4   {'learning_rate': 0.01, 'max_depth': 5, 'n_est...           0.965517   \n",
       "5   {'learning_rate': 0.01, 'max_depth': 5, 'n_est...           0.965517   \n",
       "6   {'learning_rate': 0.01, 'max_depth': 5, 'n_est...           1.000000   \n",
       "7   {'learning_rate': 0.01, 'max_depth': 5, 'n_est...           1.000000   \n",
       "8   {'learning_rate': 0.01, 'max_depth': 5, 'n_est...           1.000000   \n",
       "9   {'learning_rate': 0.01, 'max_depth': 10, 'n_es...           0.931034   \n",
       "10  {'learning_rate': 0.01, 'max_depth': 10, 'n_es...           0.931034   \n",
       "11  {'learning_rate': 0.01, 'max_depth': 10, 'n_es...           0.931034   \n",
       "12  {'learning_rate': 0.01, 'max_depth': 10, 'n_es...           0.965517   \n",
       "13  {'learning_rate': 0.01, 'max_depth': 10, 'n_es...           0.965517   \n",
       "14  {'learning_rate': 0.01, 'max_depth': 10, 'n_es...           0.965517   \n",
       "15  {'learning_rate': 0.01, 'max_depth': 10, 'n_es...           1.000000   \n",
       "16  {'learning_rate': 0.01, 'max_depth': 10, 'n_es...           1.000000   \n",
       "17  {'learning_rate': 0.01, 'max_depth': 10, 'n_es...           1.000000   \n",
       "18  {'learning_rate': 0.01, 'max_depth': 15, 'n_es...           0.931034   \n",
       "19  {'learning_rate': 0.01, 'max_depth': 15, 'n_es...           0.931034   \n",
       "20  {'learning_rate': 0.01, 'max_depth': 15, 'n_es...           0.931034   \n",
       "21  {'learning_rate': 0.01, 'max_depth': 15, 'n_es...           0.965517   \n",
       "22  {'learning_rate': 0.01, 'max_depth': 15, 'n_es...           0.965517   \n",
       "23  {'learning_rate': 0.01, 'max_depth': 15, 'n_es...           0.965517   \n",
       "24  {'learning_rate': 0.01, 'max_depth': 15, 'n_es...           1.000000   \n",
       "25  {'learning_rate': 0.01, 'max_depth': 15, 'n_es...           1.000000   \n",
       "26  {'learning_rate': 0.01, 'max_depth': 15, 'n_es...           1.000000   \n",
       "27  {'learning_rate': 0.1, 'max_depth': 5, 'n_esti...           1.000000   \n",
       "28  {'learning_rate': 0.1, 'max_depth': 5, 'n_esti...           1.000000   \n",
       "29  {'learning_rate': 0.1, 'max_depth': 5, 'n_esti...           1.000000   \n",
       "30  {'learning_rate': 0.1, 'max_depth': 5, 'n_esti...           1.000000   \n",
       "31  {'learning_rate': 0.1, 'max_depth': 5, 'n_esti...           1.000000   \n",
       "32  {'learning_rate': 0.1, 'max_depth': 5, 'n_esti...           1.000000   \n",
       "33  {'learning_rate': 0.1, 'max_depth': 5, 'n_esti...           1.000000   \n",
       "34  {'learning_rate': 0.1, 'max_depth': 5, 'n_esti...           1.000000   \n",
       "35  {'learning_rate': 0.1, 'max_depth': 5, 'n_esti...           1.000000   \n",
       "36  {'learning_rate': 0.1, 'max_depth': 10, 'n_est...           1.000000   \n",
       "37  {'learning_rate': 0.1, 'max_depth': 10, 'n_est...           1.000000   \n",
       "38  {'learning_rate': 0.1, 'max_depth': 10, 'n_est...           1.000000   \n",
       "39  {'learning_rate': 0.1, 'max_depth': 10, 'n_est...           1.000000   \n",
       "40  {'learning_rate': 0.1, 'max_depth': 10, 'n_est...           1.000000   \n",
       "41  {'learning_rate': 0.1, 'max_depth': 10, 'n_est...           1.000000   \n",
       "42  {'learning_rate': 0.1, 'max_depth': 10, 'n_est...           1.000000   \n",
       "43  {'learning_rate': 0.1, 'max_depth': 10, 'n_est...           1.000000   \n",
       "44  {'learning_rate': 0.1, 'max_depth': 10, 'n_est...           1.000000   \n",
       "45  {'learning_rate': 0.1, 'max_depth': 15, 'n_est...           1.000000   \n",
       "46  {'learning_rate': 0.1, 'max_depth': 15, 'n_est...           1.000000   \n",
       "47  {'learning_rate': 0.1, 'max_depth': 15, 'n_est...           1.000000   \n",
       "48  {'learning_rate': 0.1, 'max_depth': 15, 'n_est...           1.000000   \n",
       "49  {'learning_rate': 0.1, 'max_depth': 15, 'n_est...           1.000000   \n",
       "50  {'learning_rate': 0.1, 'max_depth': 15, 'n_est...           1.000000   \n",
       "51  {'learning_rate': 0.1, 'max_depth': 15, 'n_est...           1.000000   \n",
       "52  {'learning_rate': 0.1, 'max_depth': 15, 'n_est...           1.000000   \n",
       "53  {'learning_rate': 0.1, 'max_depth': 15, 'n_est...           1.000000   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0            0.965517           0.928571           0.857143   \n",
       "1            0.965517           0.928571           0.857143   \n",
       "2            0.965517           0.928571           0.857143   \n",
       "3            1.000000           1.000000           0.892857   \n",
       "4            1.000000           1.000000           0.892857   \n",
       "5            1.000000           1.000000           0.892857   \n",
       "6            1.000000           1.000000           0.928571   \n",
       "7            1.000000           1.000000           0.928571   \n",
       "8            1.000000           1.000000           0.928571   \n",
       "9            0.965517           0.928571           0.857143   \n",
       "10           0.965517           0.928571           0.857143   \n",
       "11           0.965517           0.928571           0.857143   \n",
       "12           1.000000           1.000000           0.892857   \n",
       "13           1.000000           1.000000           0.892857   \n",
       "14           1.000000           1.000000           0.892857   \n",
       "15           1.000000           1.000000           0.928571   \n",
       "16           1.000000           1.000000           0.928571   \n",
       "17           1.000000           1.000000           0.928571   \n",
       "18           0.965517           0.928571           0.857143   \n",
       "19           0.965517           0.928571           0.857143   \n",
       "20           0.965517           0.928571           0.857143   \n",
       "21           1.000000           1.000000           0.892857   \n",
       "22           1.000000           1.000000           0.892857   \n",
       "23           1.000000           1.000000           0.892857   \n",
       "24           1.000000           1.000000           0.928571   \n",
       "25           1.000000           1.000000           0.928571   \n",
       "26           1.000000           1.000000           0.928571   \n",
       "27           1.000000           1.000000           0.928571   \n",
       "28           1.000000           1.000000           0.928571   \n",
       "29           1.000000           1.000000           0.928571   \n",
       "30           1.000000           1.000000           0.928571   \n",
       "31           1.000000           1.000000           0.928571   \n",
       "32           1.000000           1.000000           0.928571   \n",
       "33           1.000000           1.000000           0.928571   \n",
       "34           1.000000           1.000000           0.928571   \n",
       "35           1.000000           1.000000           0.928571   \n",
       "36           1.000000           1.000000           0.928571   \n",
       "37           1.000000           1.000000           0.928571   \n",
       "38           1.000000           1.000000           0.928571   \n",
       "39           1.000000           1.000000           0.928571   \n",
       "40           1.000000           1.000000           0.928571   \n",
       "41           1.000000           1.000000           0.928571   \n",
       "42           1.000000           1.000000           0.928571   \n",
       "43           1.000000           1.000000           0.928571   \n",
       "44           1.000000           1.000000           0.928571   \n",
       "45           1.000000           1.000000           0.928571   \n",
       "46           1.000000           1.000000           0.928571   \n",
       "47           1.000000           1.000000           0.928571   \n",
       "48           1.000000           1.000000           0.928571   \n",
       "49           1.000000           1.000000           0.928571   \n",
       "50           1.000000           1.000000           0.928571   \n",
       "51           1.000000           1.000000           0.928571   \n",
       "52           1.000000           1.000000           0.928571   \n",
       "53           1.000000           1.000000           0.928571   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0            0.928571         0.922167        0.035406               46  \n",
       "1            0.928571         0.922167        0.035406               46  \n",
       "2            0.928571         0.922167        0.035406               46  \n",
       "3            0.964286         0.964532        0.039126               37  \n",
       "4            0.964286         0.964532        0.039126               37  \n",
       "5            0.964286         0.964532        0.039126               37  \n",
       "6            0.964286         0.978571        0.028571                1  \n",
       "7            0.964286         0.978571        0.028571                1  \n",
       "8            0.964286         0.978571        0.028571                1  \n",
       "9            0.928571         0.922167        0.035406               46  \n",
       "10           0.928571         0.922167        0.035406               46  \n",
       "11           0.928571         0.922167        0.035406               46  \n",
       "12           0.964286         0.964532        0.039126               37  \n",
       "13           0.964286         0.964532        0.039126               37  \n",
       "14           0.964286         0.964532        0.039126               37  \n",
       "15           0.964286         0.978571        0.028571                1  \n",
       "16           0.964286         0.978571        0.028571                1  \n",
       "17           0.964286         0.978571        0.028571                1  \n",
       "18           0.928571         0.922167        0.035406               46  \n",
       "19           0.928571         0.922167        0.035406               46  \n",
       "20           0.928571         0.922167        0.035406               46  \n",
       "21           0.964286         0.964532        0.039126               37  \n",
       "22           0.964286         0.964532        0.039126               37  \n",
       "23           0.964286         0.964532        0.039126               37  \n",
       "24           0.964286         0.978571        0.028571                1  \n",
       "25           0.964286         0.978571        0.028571                1  \n",
       "26           0.964286         0.978571        0.028571                1  \n",
       "27           0.964286         0.978571        0.028571                1  \n",
       "28           0.964286         0.978571        0.028571                1  \n",
       "29           0.964286         0.978571        0.028571                1  \n",
       "30           0.964286         0.978571        0.028571                1  \n",
       "31           0.964286         0.978571        0.028571                1  \n",
       "32           0.964286         0.978571        0.028571                1  \n",
       "33           0.964286         0.978571        0.028571                1  \n",
       "34           0.964286         0.978571        0.028571                1  \n",
       "35           0.964286         0.978571        0.028571                1  \n",
       "36           0.964286         0.978571        0.028571                1  \n",
       "37           0.964286         0.978571        0.028571                1  \n",
       "38           0.964286         0.978571        0.028571                1  \n",
       "39           0.964286         0.978571        0.028571                1  \n",
       "40           0.964286         0.978571        0.028571                1  \n",
       "41           0.964286         0.978571        0.028571                1  \n",
       "42           0.964286         0.978571        0.028571                1  \n",
       "43           0.964286         0.978571        0.028571                1  \n",
       "44           0.964286         0.978571        0.028571                1  \n",
       "45           0.964286         0.978571        0.028571                1  \n",
       "46           0.964286         0.978571        0.028571                1  \n",
       "47           0.964286         0.978571        0.028571                1  \n",
       "48           0.964286         0.978571        0.028571                1  \n",
       "49           0.964286         0.978571        0.028571                1  \n",
       "50           0.964286         0.978571        0.028571                1  \n",
       "51           0.964286         0.978571        0.028571                1  \n",
       "52           0.964286         0.978571        0.028571                1  \n",
       "53           0.964286         0.978571        0.028571                1  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1=pd.DataFrame(lgbm_hpt.cv_results_)\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6e6ebcc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_num_leaves</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.042888</td>\n",
       "      <td>0.002305</td>\n",
       "      <td>0.002022</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>20</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 5, 'n_est...</td>\n",
       "      <td>0.931034</td>\n",
       "      <td>0.965517</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.922167</td>\n",
       "      <td>0.035406</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.043524</td>\n",
       "      <td>0.003424</td>\n",
       "      <td>0.002208</td>\n",
       "      <td>0.000749</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>30</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 5, 'n_est...</td>\n",
       "      <td>0.931034</td>\n",
       "      <td>0.965517</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.922167</td>\n",
       "      <td>0.035406</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.046007</td>\n",
       "      <td>0.003709</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>0.000490</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>40</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 5, 'n_est...</td>\n",
       "      <td>0.931034</td>\n",
       "      <td>0.965517</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.922167</td>\n",
       "      <td>0.035406</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.194620</td>\n",
       "      <td>0.008163</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5</td>\n",
       "      <td>500</td>\n",
       "      <td>20</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 5, 'n_est...</td>\n",
       "      <td>0.965517</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>0.964286</td>\n",
       "      <td>0.964532</td>\n",
       "      <td>0.039126</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.190820</td>\n",
       "      <td>0.012319</td>\n",
       "      <td>0.002600</td>\n",
       "      <td>0.000490</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5</td>\n",
       "      <td>500</td>\n",
       "      <td>30</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 5, 'n_est...</td>\n",
       "      <td>0.965517</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>0.964286</td>\n",
       "      <td>0.964532</td>\n",
       "      <td>0.039126</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       0.042888      0.002305         0.002022        0.000044   \n",
       "1       0.043524      0.003424         0.002208        0.000749   \n",
       "2       0.046007      0.003709         0.001600        0.000490   \n",
       "3       0.194620      0.008163         0.003200        0.000400   \n",
       "4       0.190820      0.012319         0.002600        0.000490   \n",
       "\n",
       "  param_learning_rate param_max_depth param_n_estimators param_num_leaves  \\\n",
       "0                0.01               5                100               20   \n",
       "1                0.01               5                100               30   \n",
       "2                0.01               5                100               40   \n",
       "3                0.01               5                500               20   \n",
       "4                0.01               5                500               30   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "0  {'learning_rate': 0.01, 'max_depth': 5, 'n_est...           0.931034   \n",
       "1  {'learning_rate': 0.01, 'max_depth': 5, 'n_est...           0.931034   \n",
       "2  {'learning_rate': 0.01, 'max_depth': 5, 'n_est...           0.931034   \n",
       "3  {'learning_rate': 0.01, 'max_depth': 5, 'n_est...           0.965517   \n",
       "4  {'learning_rate': 0.01, 'max_depth': 5, 'n_est...           0.965517   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "0           0.965517           0.928571           0.857143           0.928571   \n",
       "1           0.965517           0.928571           0.857143           0.928571   \n",
       "2           0.965517           0.928571           0.857143           0.928571   \n",
       "3           1.000000           1.000000           0.892857           0.964286   \n",
       "4           1.000000           1.000000           0.892857           0.964286   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  \n",
       "0         0.922167        0.035406               46  \n",
       "1         0.922167        0.035406               46  \n",
       "2         0.922167        0.035406               46  \n",
       "3         0.964532        0.039126               37  \n",
       "4         0.964532        0.039126               37  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be50c9ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
