{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WgCAdAXHL8Da",
        "outputId": "3420fe89-e595-4943-f575-2ad8ff763e52"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.2.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2022.10.31)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.65.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('all')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oab3RCQLJkHd",
        "outputId": "436ce997-b323-4ffe-fa94-400a0285e535"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading collection 'all'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package abc to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/abc.zip.\n",
            "[nltk_data]    | Downloading package alpino to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/alpino.zip.\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping\n",
            "[nltk_data]    |       taggers/averaged_perceptron_tagger_ru.zip.\n",
            "[nltk_data]    | Downloading package basque_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/basque_grammars.zip.\n",
            "[nltk_data]    | Downloading package bcp47 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package biocreative_ppi to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/biocreative_ppi.zip.\n",
            "[nltk_data]    | Downloading package bllip_wsj_no_aux to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/bllip_wsj_no_aux.zip.\n",
            "[nltk_data]    | Downloading package book_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/book_grammars.zip.\n",
            "[nltk_data]    | Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/brown.zip.\n",
            "[nltk_data]    | Downloading package brown_tei to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/brown_tei.zip.\n",
            "[nltk_data]    | Downloading package cess_cat to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cess_cat.zip.\n",
            "[nltk_data]    | Downloading package cess_esp to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cess_esp.zip.\n",
            "[nltk_data]    | Downloading package chat80 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/chat80.zip.\n",
            "[nltk_data]    | Downloading package city_database to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/city_database.zip.\n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cmudict.zip.\n",
            "[nltk_data]    | Downloading package comparative_sentences to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/comparative_sentences.zip.\n",
            "[nltk_data]    | Downloading package comtrans to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package conll2000 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/conll2000.zip.\n",
            "[nltk_data]    | Downloading package conll2002 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/conll2002.zip.\n",
            "[nltk_data]    | Downloading package conll2007 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package crubadan to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/crubadan.zip.\n",
            "[nltk_data]    | Downloading package dependency_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/dependency_treebank.zip.\n",
            "[nltk_data]    | Downloading package dolch to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/dolch.zip.\n",
            "[nltk_data]    | Downloading package europarl_raw to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/europarl_raw.zip.\n",
            "[nltk_data]    | Downloading package extended_omw to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package floresta to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/floresta.zip.\n",
            "[nltk_data]    | Downloading package framenet_v15 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/framenet_v15.zip.\n",
            "[nltk_data]    | Downloading package framenet_v17 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/framenet_v17.zip.\n",
            "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gazetteers.zip.\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/genesis.zip.\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gutenberg.zip.\n",
            "[nltk_data]    | Downloading package ieer to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ieer.zip.\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/inaugural.zip.\n",
            "[nltk_data]    | Downloading package indian to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/indian.zip.\n",
            "[nltk_data]    | Downloading package jeita to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package kimmo to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/kimmo.zip.\n",
            "[nltk_data]    | Downloading package knbc to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package large_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/large_grammars.zip.\n",
            "[nltk_data]    | Downloading package lin_thesaurus to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/lin_thesaurus.zip.\n",
            "[nltk_data]    | Downloading package mac_morpho to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/mac_morpho.zip.\n",
            "[nltk_data]    | Downloading package machado to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package masc_tagged to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/maxent_treebank_pos_tagger.zip.\n",
            "[nltk_data]    | Downloading package moses_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/moses_sample.zip.\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/movie_reviews.zip.\n",
            "[nltk_data]    | Downloading package mte_teip5 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/mte_teip5.zip.\n",
            "[nltk_data]    | Downloading package mwa_ppdb to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping misc/mwa_ppdb.zip.\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/names.zip.\n",
            "[nltk_data]    | Downloading package nombank.1.0 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package nonbreaking_prefixes to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/nonbreaking_prefixes.zip.\n",
            "[nltk_data]    | Downloading package nps_chat to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/nps_chat.zip.\n",
            "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package opinion_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/opinion_lexicon.zip.\n",
            "[nltk_data]    | Downloading package panlex_swadesh to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package paradigms to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/paradigms.zip.\n",
            "[nltk_data]    | Downloading package pe08 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pe08.zip.\n",
            "[nltk_data]    | Downloading package perluniprops to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping misc/perluniprops.zip.\n",
            "[nltk_data]    | Downloading package pil to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pil.zip.\n",
            "[nltk_data]    | Downloading package pl196x to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pl196x.zip.\n",
            "[nltk_data]    | Downloading package porter_test to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping stemmers/porter_test.zip.\n",
            "[nltk_data]    | Downloading package ppattach to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ppattach.zip.\n",
            "[nltk_data]    | Downloading package problem_reports to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/problem_reports.zip.\n",
            "[nltk_data]    | Downloading package product_reviews_1 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/product_reviews_1.zip.\n",
            "[nltk_data]    | Downloading package product_reviews_2 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/product_reviews_2.zip.\n",
            "[nltk_data]    | Downloading package propbank to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package pros_cons to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pros_cons.zip.\n",
            "[nltk_data]    | Downloading package ptb to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ptb.zip.\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data]    | Downloading package qc to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/qc.zip.\n",
            "[nltk_data]    | Downloading package reuters to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package rslp to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping stemmers/rslp.zip.\n",
            "[nltk_data]    | Downloading package rte to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/rte.zip.\n",
            "[nltk_data]    | Downloading package sample_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/sample_grammars.zip.\n",
            "[nltk_data]    | Downloading package semcor to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package senseval to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/senseval.zip.\n",
            "[nltk_data]    | Downloading package sentence_polarity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sentence_polarity.zip.\n",
            "[nltk_data]    | Downloading package sentiwordnet to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sentiwordnet.zip.\n",
            "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/shakespeare.zip.\n",
            "[nltk_data]    | Downloading package sinica_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sinica_treebank.zip.\n",
            "[nltk_data]    | Downloading package smultron to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/smultron.zip.\n",
            "[nltk_data]    | Downloading package snowball_data to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package spanish_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/spanish_grammars.zip.\n",
            "[nltk_data]    | Downloading package state_union to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/state_union.zip.\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data]    | Downloading package subjectivity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/subjectivity.zip.\n",
            "[nltk_data]    | Downloading package swadesh to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/swadesh.zip.\n",
            "[nltk_data]    | Downloading package switchboard to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/switchboard.zip.\n",
            "[nltk_data]    | Downloading package tagsets to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping help/tagsets.zip.\n",
            "[nltk_data]    | Downloading package timit to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/timit.zip.\n",
            "[nltk_data]    | Downloading package toolbox to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/toolbox.zip.\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/treebank.zip.\n",
            "[nltk_data]    | Downloading package twitter_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/twitter_samples.zip.\n",
            "[nltk_data]    | Downloading package udhr to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/udhr.zip.\n",
            "[nltk_data]    | Downloading package udhr2 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/udhr2.zip.\n",
            "[nltk_data]    | Downloading package unicode_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/unicode_samples.zip.\n",
            "[nltk_data]    | Downloading package universal_tagset to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/universal_tagset.zip.\n",
            "[nltk_data]    | Downloading package universal_treebanks_v20 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package vader_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package verbnet to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/verbnet.zip.\n",
            "[nltk_data]    | Downloading package verbnet3 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/verbnet3.zip.\n",
            "[nltk_data]    | Downloading package webtext to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/webtext.zip.\n",
            "[nltk_data]    | Downloading package wmt15_eval to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/wmt15_eval.zip.\n",
            "[nltk_data]    | Downloading package word2vec_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/word2vec_sample.zip.\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet2021 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet2022 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet2022.zip.\n",
            "[nltk_data]    | Downloading package wordnet31 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet_ic.zip.\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/words.zip.\n",
            "[nltk_data]    | Downloading package ycoe to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ycoe.zip.\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection all\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YkMkxpXIMBrt",
        "outputId": "7bcbb202-9d78-4eea-8bdc-b6a00385c2e4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Text\n",
        "import os\n",
        "import nltk\n",
        "import nltk.corpus\n",
        "print(os.listdir(nltk.data.find('corpora')))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nc_E_499MRx4",
        "outputId": "8ddf45d0-4766-466f-a97d-06b1c6c486db"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['wordnet_ic', 'pil', 'nps_chat', 'semcor.zip', 'sinica_treebank.zip', 'problem_reports', 'rte', 'udhr2.zip', 'webtext.zip', 'conll2000', 'floresta.zip', 'wordnet2022', 'stopwords', 'framenet_v15', 'timit.zip', 'ieer.zip', 'mte_teip5', 'shakespeare', 'framenet_v17.zip', 'pe08.zip', 'unicode_samples.zip', 'senseval.zip', 'comparative_sentences.zip', 'udhr', 'gutenberg', 'paradigms.zip', 'knbc.zip', 'cess_cat', 'europarl_raw', 'brown_tei', 'lin_thesaurus', 'ieer', 'shakespeare.zip', 'jeita.zip', 'brown.zip', 'conll2007.zip', 'biocreative_ppi', 'cmudict', 'universal_treebanks_v20.zip', 'timit', 'comparative_sentences', 'smultron.zip', 'pl196x.zip', 'cess_esp.zip', 'verbnet3.zip', 'treebank', 'wordnet.zip', 'dependency_treebank', 'sentiwordnet.zip', 'product_reviews_1', 'ycoe', 'movie_reviews.zip', 'opinion_lexicon', 'pl196x', 'cmudict.zip', 'wordnet31.zip', 'conll2002', 'nonbreaking_prefixes.zip', 'udhr.zip', 'names', 'ptb', 'dolch.zip', 'conll2000.zip', 'paradigms', 'extended_omw.zip', 'qc', 'genesis', 'crubadan.zip', 'brown_tei.zip', 'gazetteers', 'framenet_v17', 'nps_chat.zip', 'abc', 'ppattach.zip', 'stopwords.zip', 'city_database.zip', 'ppattach', 'product_reviews_2', 'product_reviews_2.zip', 'webtext', 'names.zip', 'dolch', 'machado.zip', 'product_reviews_1.zip', 'chat80', 'toolbox', 'floresta', 'omw-1.4.zip', 'kimmo', 'wordnet2022.zip', 'sentence_polarity.zip', 'cess_cat.zip', 'toolbox.zip', 'udhr2', 'panlex_swadesh.zip', 'gutenberg.zip', 'nombank.1.0.zip', 'lin_thesaurus.zip', 'biocreative_ppi.zip', 'propbank.zip', 'mac_morpho.zip', 'alpino.zip', 'treebank.zip', 'words.zip', 'chat80.zip', 'rte.zip', 'wordnet2021.zip', 'swadesh', 'unicode_samples', 'alpino', 'state_union', 'omw.zip', 'opinion_lexicon.zip', 'verbnet', 'gazetteers.zip', 'pil.zip', 'pros_cons.zip', 'indian', 'senseval', 'dependency_treebank.zip', 'framenet_v15.zip', 'verbnet.zip', 'qc.zip', 'masc_tagged.zip', 'words', 'sentence_polarity', 'movie_reviews', 'inaugural', 'twitter_samples.zip', 'cess_esp', 'mac_morpho', 'mte_teip5.zip', 'city_database', 'conll2002.zip', 'kimmo.zip', 'ptb.zip', 'sinica_treebank', 'europarl_raw.zip', 'twitter_samples', 'inaugural.zip', 'comtrans.zip', 'brown', 'smultron', 'pros_cons', 'pe08', 'crubadan', 'state_union.zip', 'wordnet_ic.zip', 'nonbreaking_prefixes', 'verbnet3', 'subjectivity.zip', 'genesis.zip', 'bcp47.zip', 'indian.zip', 'problem_reports.zip', 'swadesh.zip', 'ycoe.zip', 'subjectivity', 'reuters.zip', 'abc.zip', 'switchboard.zip', 'switchboard', 'sentiwordnet']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.corpus.gutenberg.fileids()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TmyteaEcMVpe",
        "outputId": "7833846b-8da1-4236-8a1d-74743ded151e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['austen-emma.txt',\n",
              " 'austen-persuasion.txt',\n",
              " 'austen-sense.txt',\n",
              " 'bible-kjv.txt',\n",
              " 'blake-poems.txt',\n",
              " 'bryant-stories.txt',\n",
              " 'burgess-busterbrown.txt',\n",
              " 'carroll-alice.txt',\n",
              " 'chesterton-ball.txt',\n",
              " 'chesterton-brown.txt',\n",
              " 'chesterton-thursday.txt',\n",
              " 'edgeworth-parents.txt',\n",
              " 'melville-moby_dick.txt',\n",
              " 'milton-paradise.txt',\n",
              " 'shakespeare-caesar.txt',\n",
              " 'shakespeare-hamlet.txt',\n",
              " 'shakespeare-macbeth.txt',\n",
              " 'whitman-leaves.txt']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Bag of words\n",
        "text = nltk.corpus.gutenberg.words(\"shakespeare-hamlet.txt\")\n",
        "text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PCbuIN64McsM",
        "outputId": "79363b1e-8b2d-43d1-a694-880c791dfeac"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['[', 'The', 'Tragedie', 'of', 'Hamlet', 'by', ...]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for word in text[:500]:\n",
        "  print(word, sep='',end='')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pJe3VI-tNW8N",
        "outputId": "73b3f453-eb40-4b61-8dc5-eed689eed091"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TheTragedieofHamletbyWilliamShakespeare1599]ActusPrimus.ScoenaPrima.EnterBarnardoandFranciscotwoCentinels.Barnardo.Who'sthere?Fran.Nayanswerme:Stand&vnfoldyourselfeBar.LongliuetheKingFran.Barnardo?Bar.HeFran.YoucomemostcarefullyvponyourhoureBar.'Tisnowstrooktwelue,gettheetobedFranciscoFran.Forthisreleefemuchthankes:'Tisbittercold,AndIamsickeatheartBarn.HaueyouhadquietGuard?Fran.NotaMousestirringBarn.Well,goodnight.IfyoudomeetHoratioandMarcellus,theRiualsofmyWatch,bidthemmakehast.EnterHoratioandMarcellus.Fran.IthinkeIhearethem.Stand:who'sthere?Hor.FriendstothisgroundMar.AndLeige-mentotheDaneFran.GiueyougoodnightMar.OfarwelhonestSoldier,whohathrelieu'dyou?Fra.Barnardoha'smyplace:giueyougoodnight.ExitFran.Mar.HollaBarnardoBar.Say,whatisHoratiothere?Hor.ApeeceofhimBar.WelcomeHoratio,welcomegoodMarcellusMar.What,ha'sthisthingappear'dagainetonightBar.IhaueseenenothingMar.Horatiosaies,'tisbutourFantasie,AndwillnotletbeleefetakeholdofhimTouchingthisdreadedsight,twiceseeneofvs,ThereforeIhaueintreatedhimalongWithvs,towatchtheminutesofthisNight,ThatifagainethisApparitioncome,Hemayapproueoureyes,andspeaketoitHor.Tush,tush,'twillnotappeareBar.Sitdownea-while,Andletvsonceagaineassaileyoureares,ThataresofortifiedagainstourStory,WhatwetwoNightshaueseeneHor.Well,sitwedowne,AndletvsheareBarnardospeakeofthisBarn.Lastnightofall,WhenyondsameStarrethat'sWestwardfromthePoleHadmadehiscourset'illumethatpartofHeauenWherenowitburnes,Marcellusandmyselfe,TheBellthenbeatingoneMar.Peace,breaketheeof:EntertheGhost.LookewhereitcomesagaineBarn.Inthesamefigure,liketheKingthat'sdeadMar.ThouartaScholler;speaketoitHoratioBarn.LookesitnotliketheKing?MarkeitHoratioHora.Mostlike:Itharrowesmewithfear&wonderBarn.ItwouldbespoketooMar.QuestionitHoratioHor.Whatart"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for word in text[:500]:\n",
        "  print(word, sep=' ',end=' ')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qbTBQ_u7Nfbx",
        "outputId": "a5654dc8-828b-417b-ec05-c4812b1401f0"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ The Tragedie of Hamlet by William Shakespeare 1599 ] Actus Primus . Scoena Prima . Enter Barnardo and Francisco two Centinels . Barnardo . Who ' s there ? Fran . Nay answer me : Stand & vnfold your selfe Bar . Long liue the King Fran . Barnardo ? Bar . He Fran . You come most carefully vpon your houre Bar . ' Tis now strook twelue , get thee to bed Francisco Fran . For this releefe much thankes : ' Tis bitter cold , And I am sicke at heart Barn . Haue you had quiet Guard ? Fran . Not a Mouse stirring Barn . Well , goodnight . If you do meet Horatio and Marcellus , the Riuals of my Watch , bid them make hast . Enter Horatio and Marcellus . Fran . I thinke I heare them . Stand : who ' s there ? Hor . Friends to this ground Mar . And Leige - men to the Dane Fran . Giue you good night Mar . O farwel honest Soldier , who hath relieu ' d you ? Fra . Barnardo ha ' s my place : giue you goodnight . Exit Fran . Mar . Holla Barnardo Bar . Say , what is Horatio there ? Hor . A peece of him Bar . Welcome Horatio , welcome good Marcellus Mar . What , ha ' s this thing appear ' d againe to night Bar . I haue seene nothing Mar . Horatio saies , ' tis but our Fantasie , And will not let beleefe take hold of him Touching this dreaded sight , twice seene of vs , Therefore I haue intreated him along With vs , to watch the minutes of this Night , That if againe this Apparition come , He may approue our eyes , and speake to it Hor . Tush , tush , ' twill not appeare Bar . Sit downe a - while , And let vs once againe assaile your eares , That are so fortified against our Story , What we two Nights haue seene Hor . Well , sit we downe , And let vs heare Barnardo speake of this Barn . Last night of all , When yond same Starre that ' s Westward from the Pole Had made his course t ' illume that part of Heauen Where now it burnes , Marcellus and my selfe , The Bell then beating one Mar . Peace , breake thee of : Enter the Ghost . Looke where it comes againe Barn . In the same figure , like the King that ' s dead Mar . Thou art a Scholler ; speake to it Horatio Barn . Lookes it not like the King ? Marke it Horatio Hora . Most like : It harrowes me with fear & wonder Barn . It would be spoke too Mar . Question it Horatio Hor . What art "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = 'AI technologies have a wide range of applications, including voice assistants, image recognition, autonomous vehicles, recommendation systems, fraud detection, and much more. The field of AI continues to advance rapidly, with ongoing research and development to enhance its capabilities and impact across industries and sectors.'\n",
        "text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "teurHBItNvSG",
        "outputId": "69b235cc-c9c8-44cb-fe19-13310a8b1bd6"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'AI technologies have a wide range of applications, including voice assistants, image recognition, autonomous vehicles, recommendation systems, fraud detection, and much more. The field of AI continues to advance rapidly, with ongoing research and development to enhance its capabilities and impact across industries and sectors.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pDbMq8lkOFb1",
        "outputId": "f74b4d15-5d24-4a9a-dc98-f2deb0daaad4"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "str"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokens\n",
        "tokens = nltk.word_tokenize(text)\n",
        "tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "faesFMLdONHK",
        "outputId": "63d98cb8-f185-4918-d25b-5583a2da1ed9"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['AI',\n",
              " 'technologies',\n",
              " 'have',\n",
              " 'a',\n",
              " 'wide',\n",
              " 'range',\n",
              " 'of',\n",
              " 'applications',\n",
              " ',',\n",
              " 'including',\n",
              " 'voice',\n",
              " 'assistants',\n",
              " ',',\n",
              " 'image',\n",
              " 'recognition',\n",
              " ',',\n",
              " 'autonomous',\n",
              " 'vehicles',\n",
              " ',',\n",
              " 'recommendation',\n",
              " 'systems',\n",
              " ',',\n",
              " 'fraud',\n",
              " 'detection',\n",
              " ',',\n",
              " 'and',\n",
              " 'much',\n",
              " 'more',\n",
              " '.',\n",
              " 'The',\n",
              " 'field',\n",
              " 'of',\n",
              " 'AI',\n",
              " 'continues',\n",
              " 'to',\n",
              " 'advance',\n",
              " 'rapidly',\n",
              " ',',\n",
              " 'with',\n",
              " 'ongoing',\n",
              " 'research',\n",
              " 'and',\n",
              " 'development',\n",
              " 'to',\n",
              " 'enhance',\n",
              " 'its',\n",
              " 'capabilities',\n",
              " 'and',\n",
              " 'impact',\n",
              " 'across',\n",
              " 'industries',\n",
              " 'and',\n",
              " 'sectors',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dDpq_Fj2OUWu",
        "outputId": "036b7db3-bf7a-40ac-9f64-8b26143d53b3"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "54"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.probability import FreqDist\n",
        "fdist = FreqDist()"
      ],
      "metadata": {
        "id": "KBp_1dHwOipM"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for word in tokens:\n",
        "  fdist[word.lower()]+=1\n",
        "fdist"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mBk4bTInOsWn",
        "outputId": "3cd0bd01-2d2e-4db1-923f-032b2e91c35a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FreqDist({',': 7, 'and': 4, 'ai': 2, 'of': 2, '.': 2, 'to': 2, 'technologies': 1, 'have': 1, 'a': 1, 'wide': 1, ...})"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fdist_top10 = fdist.most_common(10)\n",
        "fdist_top10"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6D1rT0u2O1iA",
        "outputId": "0c2a21c8-f5ff-4951-d787-a9cb1482d355"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(',', 7),\n",
              " ('and', 4),\n",
              " ('ai', 2),\n",
              " ('of', 2),\n",
              " ('.', 2),\n",
              " ('to', 2),\n",
              " ('technologies', 1),\n",
              " ('have', 1),\n",
              " ('a', 1),\n",
              " ('wide', 1)]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import blankline_tokenize\n",
        "blank = blankline_tokenize(text)\n",
        "len(blank)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1VIxiULfPIav",
        "outputId": "b6fe5061-877c-49da-b599-e521573b87fc"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.util import bigrams, trigrams, ngrams\n",
        "string = 'Public speaking refers to the act of delivering a speech or presentation to an audience in a formal setting. It involves effectively communicating ideas, information, or messages to engage, inform, or persuade the listeners.Public speaking skills are valuable in various professional and personal settings, including business presentations, conferences, seminars, academic settings, and social events. It involves elements such as speech preparation, organization, delivery, body language, voice modulation, and connecting with the audience. Mastering public speaking can help build confidence, enhance communication skills, and make a positive impact on the audience. Practice, preparation, and effective communication techniques are essential for becoming a proficient public speaker.'\n",
        "ps_tokens = nltk.word_tokenize(string)\n",
        "ps_tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n_KXiHyRQdhH",
        "outputId": "35c2d53f-e629-4884-e726-3cfa66b03b9a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Public',\n",
              " 'speaking',\n",
              " 'refers',\n",
              " 'to',\n",
              " 'the',\n",
              " 'act',\n",
              " 'of',\n",
              " 'delivering',\n",
              " 'a',\n",
              " 'speech',\n",
              " 'or',\n",
              " 'presentation',\n",
              " 'to',\n",
              " 'an',\n",
              " 'audience',\n",
              " 'in',\n",
              " 'a',\n",
              " 'formal',\n",
              " 'setting',\n",
              " '.',\n",
              " 'It',\n",
              " 'involves',\n",
              " 'effectively',\n",
              " 'communicating',\n",
              " 'ideas',\n",
              " ',',\n",
              " 'information',\n",
              " ',',\n",
              " 'or',\n",
              " 'messages',\n",
              " 'to',\n",
              " 'engage',\n",
              " ',',\n",
              " 'inform',\n",
              " ',',\n",
              " 'or',\n",
              " 'persuade',\n",
              " 'the',\n",
              " 'listeners.Public',\n",
              " 'speaking',\n",
              " 'skills',\n",
              " 'are',\n",
              " 'valuable',\n",
              " 'in',\n",
              " 'various',\n",
              " 'professional',\n",
              " 'and',\n",
              " 'personal',\n",
              " 'settings',\n",
              " ',',\n",
              " 'including',\n",
              " 'business',\n",
              " 'presentations',\n",
              " ',',\n",
              " 'conferences',\n",
              " ',',\n",
              " 'seminars',\n",
              " ',',\n",
              " 'academic',\n",
              " 'settings',\n",
              " ',',\n",
              " 'and',\n",
              " 'social',\n",
              " 'events',\n",
              " '.',\n",
              " 'It',\n",
              " 'involves',\n",
              " 'elements',\n",
              " 'such',\n",
              " 'as',\n",
              " 'speech',\n",
              " 'preparation',\n",
              " ',',\n",
              " 'organization',\n",
              " ',',\n",
              " 'delivery',\n",
              " ',',\n",
              " 'body',\n",
              " 'language',\n",
              " ',',\n",
              " 'voice',\n",
              " 'modulation',\n",
              " ',',\n",
              " 'and',\n",
              " 'connecting',\n",
              " 'with',\n",
              " 'the',\n",
              " 'audience',\n",
              " '.',\n",
              " 'Mastering',\n",
              " 'public',\n",
              " 'speaking',\n",
              " 'can',\n",
              " 'help',\n",
              " 'build',\n",
              " 'confidence',\n",
              " ',',\n",
              " 'enhance',\n",
              " 'communication',\n",
              " 'skills',\n",
              " ',',\n",
              " 'and',\n",
              " 'make',\n",
              " 'a',\n",
              " 'positive',\n",
              " 'impact',\n",
              " 'on',\n",
              " 'the',\n",
              " 'audience',\n",
              " '.',\n",
              " 'Practice',\n",
              " ',',\n",
              " 'preparation',\n",
              " ',',\n",
              " 'and',\n",
              " 'effective',\n",
              " 'communication',\n",
              " 'techniques',\n",
              " 'are',\n",
              " 'essential',\n",
              " 'for',\n",
              " 'becoming',\n",
              " 'a',\n",
              " 'proficient',\n",
              " 'public',\n",
              " 'speaker',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# BiGrams\n",
        "ps_bigrams = list(nltk.bigrams(ps_tokens))\n",
        "ps_bigrams"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vRpNwM3KRFEx",
        "outputId": "93b29783-9e9c-46f2-fa0a-6b6ef5b0bf56"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Public', 'speaking'),\n",
              " ('speaking', 'refers'),\n",
              " ('refers', 'to'),\n",
              " ('to', 'the'),\n",
              " ('the', 'act'),\n",
              " ('act', 'of'),\n",
              " ('of', 'delivering'),\n",
              " ('delivering', 'a'),\n",
              " ('a', 'speech'),\n",
              " ('speech', 'or'),\n",
              " ('or', 'presentation'),\n",
              " ('presentation', 'to'),\n",
              " ('to', 'an'),\n",
              " ('an', 'audience'),\n",
              " ('audience', 'in'),\n",
              " ('in', 'a'),\n",
              " ('a', 'formal'),\n",
              " ('formal', 'setting'),\n",
              " ('setting', '.'),\n",
              " ('.', 'It'),\n",
              " ('It', 'involves'),\n",
              " ('involves', 'effectively'),\n",
              " ('effectively', 'communicating'),\n",
              " ('communicating', 'ideas'),\n",
              " ('ideas', ','),\n",
              " (',', 'information'),\n",
              " ('information', ','),\n",
              " (',', 'or'),\n",
              " ('or', 'messages'),\n",
              " ('messages', 'to'),\n",
              " ('to', 'engage'),\n",
              " ('engage', ','),\n",
              " (',', 'inform'),\n",
              " ('inform', ','),\n",
              " (',', 'or'),\n",
              " ('or', 'persuade'),\n",
              " ('persuade', 'the'),\n",
              " ('the', 'listeners.Public'),\n",
              " ('listeners.Public', 'speaking'),\n",
              " ('speaking', 'skills'),\n",
              " ('skills', 'are'),\n",
              " ('are', 'valuable'),\n",
              " ('valuable', 'in'),\n",
              " ('in', 'various'),\n",
              " ('various', 'professional'),\n",
              " ('professional', 'and'),\n",
              " ('and', 'personal'),\n",
              " ('personal', 'settings'),\n",
              " ('settings', ','),\n",
              " (',', 'including'),\n",
              " ('including', 'business'),\n",
              " ('business', 'presentations'),\n",
              " ('presentations', ','),\n",
              " (',', 'conferences'),\n",
              " ('conferences', ','),\n",
              " (',', 'seminars'),\n",
              " ('seminars', ','),\n",
              " (',', 'academic'),\n",
              " ('academic', 'settings'),\n",
              " ('settings', ','),\n",
              " (',', 'and'),\n",
              " ('and', 'social'),\n",
              " ('social', 'events'),\n",
              " ('events', '.'),\n",
              " ('.', 'It'),\n",
              " ('It', 'involves'),\n",
              " ('involves', 'elements'),\n",
              " ('elements', 'such'),\n",
              " ('such', 'as'),\n",
              " ('as', 'speech'),\n",
              " ('speech', 'preparation'),\n",
              " ('preparation', ','),\n",
              " (',', 'organization'),\n",
              " ('organization', ','),\n",
              " (',', 'delivery'),\n",
              " ('delivery', ','),\n",
              " (',', 'body'),\n",
              " ('body', 'language'),\n",
              " ('language', ','),\n",
              " (',', 'voice'),\n",
              " ('voice', 'modulation'),\n",
              " ('modulation', ','),\n",
              " (',', 'and'),\n",
              " ('and', 'connecting'),\n",
              " ('connecting', 'with'),\n",
              " ('with', 'the'),\n",
              " ('the', 'audience'),\n",
              " ('audience', '.'),\n",
              " ('.', 'Mastering'),\n",
              " ('Mastering', 'public'),\n",
              " ('public', 'speaking'),\n",
              " ('speaking', 'can'),\n",
              " ('can', 'help'),\n",
              " ('help', 'build'),\n",
              " ('build', 'confidence'),\n",
              " ('confidence', ','),\n",
              " (',', 'enhance'),\n",
              " ('enhance', 'communication'),\n",
              " ('communication', 'skills'),\n",
              " ('skills', ','),\n",
              " (',', 'and'),\n",
              " ('and', 'make'),\n",
              " ('make', 'a'),\n",
              " ('a', 'positive'),\n",
              " ('positive', 'impact'),\n",
              " ('impact', 'on'),\n",
              " ('on', 'the'),\n",
              " ('the', 'audience'),\n",
              " ('audience', '.'),\n",
              " ('.', 'Practice'),\n",
              " ('Practice', ','),\n",
              " (',', 'preparation'),\n",
              " ('preparation', ','),\n",
              " (',', 'and'),\n",
              " ('and', 'effective'),\n",
              " ('effective', 'communication'),\n",
              " ('communication', 'techniques'),\n",
              " ('techniques', 'are'),\n",
              " ('are', 'essential'),\n",
              " ('essential', 'for'),\n",
              " ('for', 'becoming'),\n",
              " ('becoming', 'a'),\n",
              " ('a', 'proficient'),\n",
              " ('proficient', 'public'),\n",
              " ('public', 'speaker'),\n",
              " ('speaker', '.')]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# uni-gram\n",
        "ps_unigram = list(nltk.ngrams(ps_tokens,1))\n",
        "ps_unigram"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DYBFAQshRYx-",
        "outputId": "1c4473f3-944d-480c-ae52-2b4c9fe45d64"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Public',),\n",
              " ('speaking',),\n",
              " ('refers',),\n",
              " ('to',),\n",
              " ('the',),\n",
              " ('act',),\n",
              " ('of',),\n",
              " ('delivering',),\n",
              " ('a',),\n",
              " ('speech',),\n",
              " ('or',),\n",
              " ('presentation',),\n",
              " ('to',),\n",
              " ('an',),\n",
              " ('audience',),\n",
              " ('in',),\n",
              " ('a',),\n",
              " ('formal',),\n",
              " ('setting',),\n",
              " ('.',),\n",
              " ('It',),\n",
              " ('involves',),\n",
              " ('effectively',),\n",
              " ('communicating',),\n",
              " ('ideas',),\n",
              " (',',),\n",
              " ('information',),\n",
              " (',',),\n",
              " ('or',),\n",
              " ('messages',),\n",
              " ('to',),\n",
              " ('engage',),\n",
              " (',',),\n",
              " ('inform',),\n",
              " (',',),\n",
              " ('or',),\n",
              " ('persuade',),\n",
              " ('the',),\n",
              " ('listeners.Public',),\n",
              " ('speaking',),\n",
              " ('skills',),\n",
              " ('are',),\n",
              " ('valuable',),\n",
              " ('in',),\n",
              " ('various',),\n",
              " ('professional',),\n",
              " ('and',),\n",
              " ('personal',),\n",
              " ('settings',),\n",
              " (',',),\n",
              " ('including',),\n",
              " ('business',),\n",
              " ('presentations',),\n",
              " (',',),\n",
              " ('conferences',),\n",
              " (',',),\n",
              " ('seminars',),\n",
              " (',',),\n",
              " ('academic',),\n",
              " ('settings',),\n",
              " (',',),\n",
              " ('and',),\n",
              " ('social',),\n",
              " ('events',),\n",
              " ('.',),\n",
              " ('It',),\n",
              " ('involves',),\n",
              " ('elements',),\n",
              " ('such',),\n",
              " ('as',),\n",
              " ('speech',),\n",
              " ('preparation',),\n",
              " (',',),\n",
              " ('organization',),\n",
              " (',',),\n",
              " ('delivery',),\n",
              " (',',),\n",
              " ('body',),\n",
              " ('language',),\n",
              " (',',),\n",
              " ('voice',),\n",
              " ('modulation',),\n",
              " (',',),\n",
              " ('and',),\n",
              " ('connecting',),\n",
              " ('with',),\n",
              " ('the',),\n",
              " ('audience',),\n",
              " ('.',),\n",
              " ('Mastering',),\n",
              " ('public',),\n",
              " ('speaking',),\n",
              " ('can',),\n",
              " ('help',),\n",
              " ('build',),\n",
              " ('confidence',),\n",
              " (',',),\n",
              " ('enhance',),\n",
              " ('communication',),\n",
              " ('skills',),\n",
              " (',',),\n",
              " ('and',),\n",
              " ('make',),\n",
              " ('a',),\n",
              " ('positive',),\n",
              " ('impact',),\n",
              " ('on',),\n",
              " ('the',),\n",
              " ('audience',),\n",
              " ('.',),\n",
              " ('Practice',),\n",
              " (',',),\n",
              " ('preparation',),\n",
              " (',',),\n",
              " ('and',),\n",
              " ('effective',),\n",
              " ('communication',),\n",
              " ('techniques',),\n",
              " ('are',),\n",
              " ('essential',),\n",
              " ('for',),\n",
              " ('becoming',),\n",
              " ('a',),\n",
              " ('proficient',),\n",
              " ('public',),\n",
              " ('speaker',),\n",
              " ('.',)]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tri_grams\n",
        "tri_grams = list(nltk.trigrams(ps_tokens))\n",
        "tri_grams"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vIByyKB2SCAP",
        "outputId": "7632501a-b76d-4859-f1e8-3c6117dbc446"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Public', 'speaking', 'refers'),\n",
              " ('speaking', 'refers', 'to'),\n",
              " ('refers', 'to', 'the'),\n",
              " ('to', 'the', 'act'),\n",
              " ('the', 'act', 'of'),\n",
              " ('act', 'of', 'delivering'),\n",
              " ('of', 'delivering', 'a'),\n",
              " ('delivering', 'a', 'speech'),\n",
              " ('a', 'speech', 'or'),\n",
              " ('speech', 'or', 'presentation'),\n",
              " ('or', 'presentation', 'to'),\n",
              " ('presentation', 'to', 'an'),\n",
              " ('to', 'an', 'audience'),\n",
              " ('an', 'audience', 'in'),\n",
              " ('audience', 'in', 'a'),\n",
              " ('in', 'a', 'formal'),\n",
              " ('a', 'formal', 'setting'),\n",
              " ('formal', 'setting', '.'),\n",
              " ('setting', '.', 'It'),\n",
              " ('.', 'It', 'involves'),\n",
              " ('It', 'involves', 'effectively'),\n",
              " ('involves', 'effectively', 'communicating'),\n",
              " ('effectively', 'communicating', 'ideas'),\n",
              " ('communicating', 'ideas', ','),\n",
              " ('ideas', ',', 'information'),\n",
              " (',', 'information', ','),\n",
              " ('information', ',', 'or'),\n",
              " (',', 'or', 'messages'),\n",
              " ('or', 'messages', 'to'),\n",
              " ('messages', 'to', 'engage'),\n",
              " ('to', 'engage', ','),\n",
              " ('engage', ',', 'inform'),\n",
              " (',', 'inform', ','),\n",
              " ('inform', ',', 'or'),\n",
              " (',', 'or', 'persuade'),\n",
              " ('or', 'persuade', 'the'),\n",
              " ('persuade', 'the', 'listeners.Public'),\n",
              " ('the', 'listeners.Public', 'speaking'),\n",
              " ('listeners.Public', 'speaking', 'skills'),\n",
              " ('speaking', 'skills', 'are'),\n",
              " ('skills', 'are', 'valuable'),\n",
              " ('are', 'valuable', 'in'),\n",
              " ('valuable', 'in', 'various'),\n",
              " ('in', 'various', 'professional'),\n",
              " ('various', 'professional', 'and'),\n",
              " ('professional', 'and', 'personal'),\n",
              " ('and', 'personal', 'settings'),\n",
              " ('personal', 'settings', ','),\n",
              " ('settings', ',', 'including'),\n",
              " (',', 'including', 'business'),\n",
              " ('including', 'business', 'presentations'),\n",
              " ('business', 'presentations', ','),\n",
              " ('presentations', ',', 'conferences'),\n",
              " (',', 'conferences', ','),\n",
              " ('conferences', ',', 'seminars'),\n",
              " (',', 'seminars', ','),\n",
              " ('seminars', ',', 'academic'),\n",
              " (',', 'academic', 'settings'),\n",
              " ('academic', 'settings', ','),\n",
              " ('settings', ',', 'and'),\n",
              " (',', 'and', 'social'),\n",
              " ('and', 'social', 'events'),\n",
              " ('social', 'events', '.'),\n",
              " ('events', '.', 'It'),\n",
              " ('.', 'It', 'involves'),\n",
              " ('It', 'involves', 'elements'),\n",
              " ('involves', 'elements', 'such'),\n",
              " ('elements', 'such', 'as'),\n",
              " ('such', 'as', 'speech'),\n",
              " ('as', 'speech', 'preparation'),\n",
              " ('speech', 'preparation', ','),\n",
              " ('preparation', ',', 'organization'),\n",
              " (',', 'organization', ','),\n",
              " ('organization', ',', 'delivery'),\n",
              " (',', 'delivery', ','),\n",
              " ('delivery', ',', 'body'),\n",
              " (',', 'body', 'language'),\n",
              " ('body', 'language', ','),\n",
              " ('language', ',', 'voice'),\n",
              " (',', 'voice', 'modulation'),\n",
              " ('voice', 'modulation', ','),\n",
              " ('modulation', ',', 'and'),\n",
              " (',', 'and', 'connecting'),\n",
              " ('and', 'connecting', 'with'),\n",
              " ('connecting', 'with', 'the'),\n",
              " ('with', 'the', 'audience'),\n",
              " ('the', 'audience', '.'),\n",
              " ('audience', '.', 'Mastering'),\n",
              " ('.', 'Mastering', 'public'),\n",
              " ('Mastering', 'public', 'speaking'),\n",
              " ('public', 'speaking', 'can'),\n",
              " ('speaking', 'can', 'help'),\n",
              " ('can', 'help', 'build'),\n",
              " ('help', 'build', 'confidence'),\n",
              " ('build', 'confidence', ','),\n",
              " ('confidence', ',', 'enhance'),\n",
              " (',', 'enhance', 'communication'),\n",
              " ('enhance', 'communication', 'skills'),\n",
              " ('communication', 'skills', ','),\n",
              " ('skills', ',', 'and'),\n",
              " (',', 'and', 'make'),\n",
              " ('and', 'make', 'a'),\n",
              " ('make', 'a', 'positive'),\n",
              " ('a', 'positive', 'impact'),\n",
              " ('positive', 'impact', 'on'),\n",
              " ('impact', 'on', 'the'),\n",
              " ('on', 'the', 'audience'),\n",
              " ('the', 'audience', '.'),\n",
              " ('audience', '.', 'Practice'),\n",
              " ('.', 'Practice', ','),\n",
              " ('Practice', ',', 'preparation'),\n",
              " (',', 'preparation', ','),\n",
              " ('preparation', ',', 'and'),\n",
              " (',', 'and', 'effective'),\n",
              " ('and', 'effective', 'communication'),\n",
              " ('effective', 'communication', 'techniques'),\n",
              " ('communication', 'techniques', 'are'),\n",
              " ('techniques', 'are', 'essential'),\n",
              " ('are', 'essential', 'for'),\n",
              " ('essential', 'for', 'becoming'),\n",
              " ('for', 'becoming', 'a'),\n",
              " ('becoming', 'a', 'proficient'),\n",
              " ('a', 'proficient', 'public'),\n",
              " ('proficient', 'public', 'speaker'),\n",
              " ('public', 'speaker', '.')]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# N_grams\n",
        "n_grams = list(nltk.ngrams(ps_tokens,4))\n",
        "n_grams"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uYHAwsQFSb_D",
        "outputId": "e8bc5869-dcf4-4124-c18a-aba106e866cb"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Public', 'speaking', 'refers', 'to'),\n",
              " ('speaking', 'refers', 'to', 'the'),\n",
              " ('refers', 'to', 'the', 'act'),\n",
              " ('to', 'the', 'act', 'of'),\n",
              " ('the', 'act', 'of', 'delivering'),\n",
              " ('act', 'of', 'delivering', 'a'),\n",
              " ('of', 'delivering', 'a', 'speech'),\n",
              " ('delivering', 'a', 'speech', 'or'),\n",
              " ('a', 'speech', 'or', 'presentation'),\n",
              " ('speech', 'or', 'presentation', 'to'),\n",
              " ('or', 'presentation', 'to', 'an'),\n",
              " ('presentation', 'to', 'an', 'audience'),\n",
              " ('to', 'an', 'audience', 'in'),\n",
              " ('an', 'audience', 'in', 'a'),\n",
              " ('audience', 'in', 'a', 'formal'),\n",
              " ('in', 'a', 'formal', 'setting'),\n",
              " ('a', 'formal', 'setting', '.'),\n",
              " ('formal', 'setting', '.', 'It'),\n",
              " ('setting', '.', 'It', 'involves'),\n",
              " ('.', 'It', 'involves', 'effectively'),\n",
              " ('It', 'involves', 'effectively', 'communicating'),\n",
              " ('involves', 'effectively', 'communicating', 'ideas'),\n",
              " ('effectively', 'communicating', 'ideas', ','),\n",
              " ('communicating', 'ideas', ',', 'information'),\n",
              " ('ideas', ',', 'information', ','),\n",
              " (',', 'information', ',', 'or'),\n",
              " ('information', ',', 'or', 'messages'),\n",
              " (',', 'or', 'messages', 'to'),\n",
              " ('or', 'messages', 'to', 'engage'),\n",
              " ('messages', 'to', 'engage', ','),\n",
              " ('to', 'engage', ',', 'inform'),\n",
              " ('engage', ',', 'inform', ','),\n",
              " (',', 'inform', ',', 'or'),\n",
              " ('inform', ',', 'or', 'persuade'),\n",
              " (',', 'or', 'persuade', 'the'),\n",
              " ('or', 'persuade', 'the', 'listeners.Public'),\n",
              " ('persuade', 'the', 'listeners.Public', 'speaking'),\n",
              " ('the', 'listeners.Public', 'speaking', 'skills'),\n",
              " ('listeners.Public', 'speaking', 'skills', 'are'),\n",
              " ('speaking', 'skills', 'are', 'valuable'),\n",
              " ('skills', 'are', 'valuable', 'in'),\n",
              " ('are', 'valuable', 'in', 'various'),\n",
              " ('valuable', 'in', 'various', 'professional'),\n",
              " ('in', 'various', 'professional', 'and'),\n",
              " ('various', 'professional', 'and', 'personal'),\n",
              " ('professional', 'and', 'personal', 'settings'),\n",
              " ('and', 'personal', 'settings', ','),\n",
              " ('personal', 'settings', ',', 'including'),\n",
              " ('settings', ',', 'including', 'business'),\n",
              " (',', 'including', 'business', 'presentations'),\n",
              " ('including', 'business', 'presentations', ','),\n",
              " ('business', 'presentations', ',', 'conferences'),\n",
              " ('presentations', ',', 'conferences', ','),\n",
              " (',', 'conferences', ',', 'seminars'),\n",
              " ('conferences', ',', 'seminars', ','),\n",
              " (',', 'seminars', ',', 'academic'),\n",
              " ('seminars', ',', 'academic', 'settings'),\n",
              " (',', 'academic', 'settings', ','),\n",
              " ('academic', 'settings', ',', 'and'),\n",
              " ('settings', ',', 'and', 'social'),\n",
              " (',', 'and', 'social', 'events'),\n",
              " ('and', 'social', 'events', '.'),\n",
              " ('social', 'events', '.', 'It'),\n",
              " ('events', '.', 'It', 'involves'),\n",
              " ('.', 'It', 'involves', 'elements'),\n",
              " ('It', 'involves', 'elements', 'such'),\n",
              " ('involves', 'elements', 'such', 'as'),\n",
              " ('elements', 'such', 'as', 'speech'),\n",
              " ('such', 'as', 'speech', 'preparation'),\n",
              " ('as', 'speech', 'preparation', ','),\n",
              " ('speech', 'preparation', ',', 'organization'),\n",
              " ('preparation', ',', 'organization', ','),\n",
              " (',', 'organization', ',', 'delivery'),\n",
              " ('organization', ',', 'delivery', ','),\n",
              " (',', 'delivery', ',', 'body'),\n",
              " ('delivery', ',', 'body', 'language'),\n",
              " (',', 'body', 'language', ','),\n",
              " ('body', 'language', ',', 'voice'),\n",
              " ('language', ',', 'voice', 'modulation'),\n",
              " (',', 'voice', 'modulation', ','),\n",
              " ('voice', 'modulation', ',', 'and'),\n",
              " ('modulation', ',', 'and', 'connecting'),\n",
              " (',', 'and', 'connecting', 'with'),\n",
              " ('and', 'connecting', 'with', 'the'),\n",
              " ('connecting', 'with', 'the', 'audience'),\n",
              " ('with', 'the', 'audience', '.'),\n",
              " ('the', 'audience', '.', 'Mastering'),\n",
              " ('audience', '.', 'Mastering', 'public'),\n",
              " ('.', 'Mastering', 'public', 'speaking'),\n",
              " ('Mastering', 'public', 'speaking', 'can'),\n",
              " ('public', 'speaking', 'can', 'help'),\n",
              " ('speaking', 'can', 'help', 'build'),\n",
              " ('can', 'help', 'build', 'confidence'),\n",
              " ('help', 'build', 'confidence', ','),\n",
              " ('build', 'confidence', ',', 'enhance'),\n",
              " ('confidence', ',', 'enhance', 'communication'),\n",
              " (',', 'enhance', 'communication', 'skills'),\n",
              " ('enhance', 'communication', 'skills', ','),\n",
              " ('communication', 'skills', ',', 'and'),\n",
              " ('skills', ',', 'and', 'make'),\n",
              " (',', 'and', 'make', 'a'),\n",
              " ('and', 'make', 'a', 'positive'),\n",
              " ('make', 'a', 'positive', 'impact'),\n",
              " ('a', 'positive', 'impact', 'on'),\n",
              " ('positive', 'impact', 'on', 'the'),\n",
              " ('impact', 'on', 'the', 'audience'),\n",
              " ('on', 'the', 'audience', '.'),\n",
              " ('the', 'audience', '.', 'Practice'),\n",
              " ('audience', '.', 'Practice', ','),\n",
              " ('.', 'Practice', ',', 'preparation'),\n",
              " ('Practice', ',', 'preparation', ','),\n",
              " (',', 'preparation', ',', 'and'),\n",
              " ('preparation', ',', 'and', 'effective'),\n",
              " (',', 'and', 'effective', 'communication'),\n",
              " ('and', 'effective', 'communication', 'techniques'),\n",
              " ('effective', 'communication', 'techniques', 'are'),\n",
              " ('communication', 'techniques', 'are', 'essential'),\n",
              " ('techniques', 'are', 'essential', 'for'),\n",
              " ('are', 'essential', 'for', 'becoming'),\n",
              " ('essential', 'for', 'becoming', 'a'),\n",
              " ('for', 'becoming', 'a', 'proficient'),\n",
              " ('becoming', 'a', 'proficient', 'public'),\n",
              " ('a', 'proficient', 'public', 'speaker'),\n",
              " ('proficient', 'public', 'speaker', '.')]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_grams = list(nltk.ngrams(ps_tokens,5))\n",
        "n_grams"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NrJS7TC2Sq2-",
        "outputId": "b071e67b-fcfd-4441-e75c-15b764bbc809"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Public', 'speaking', 'refers', 'to', 'the'),\n",
              " ('speaking', 'refers', 'to', 'the', 'act'),\n",
              " ('refers', 'to', 'the', 'act', 'of'),\n",
              " ('to', 'the', 'act', 'of', 'delivering'),\n",
              " ('the', 'act', 'of', 'delivering', 'a'),\n",
              " ('act', 'of', 'delivering', 'a', 'speech'),\n",
              " ('of', 'delivering', 'a', 'speech', 'or'),\n",
              " ('delivering', 'a', 'speech', 'or', 'presentation'),\n",
              " ('a', 'speech', 'or', 'presentation', 'to'),\n",
              " ('speech', 'or', 'presentation', 'to', 'an'),\n",
              " ('or', 'presentation', 'to', 'an', 'audience'),\n",
              " ('presentation', 'to', 'an', 'audience', 'in'),\n",
              " ('to', 'an', 'audience', 'in', 'a'),\n",
              " ('an', 'audience', 'in', 'a', 'formal'),\n",
              " ('audience', 'in', 'a', 'formal', 'setting'),\n",
              " ('in', 'a', 'formal', 'setting', '.'),\n",
              " ('a', 'formal', 'setting', '.', 'It'),\n",
              " ('formal', 'setting', '.', 'It', 'involves'),\n",
              " ('setting', '.', 'It', 'involves', 'effectively'),\n",
              " ('.', 'It', 'involves', 'effectively', 'communicating'),\n",
              " ('It', 'involves', 'effectively', 'communicating', 'ideas'),\n",
              " ('involves', 'effectively', 'communicating', 'ideas', ','),\n",
              " ('effectively', 'communicating', 'ideas', ',', 'information'),\n",
              " ('communicating', 'ideas', ',', 'information', ','),\n",
              " ('ideas', ',', 'information', ',', 'or'),\n",
              " (',', 'information', ',', 'or', 'messages'),\n",
              " ('information', ',', 'or', 'messages', 'to'),\n",
              " (',', 'or', 'messages', 'to', 'engage'),\n",
              " ('or', 'messages', 'to', 'engage', ','),\n",
              " ('messages', 'to', 'engage', ',', 'inform'),\n",
              " ('to', 'engage', ',', 'inform', ','),\n",
              " ('engage', ',', 'inform', ',', 'or'),\n",
              " (',', 'inform', ',', 'or', 'persuade'),\n",
              " ('inform', ',', 'or', 'persuade', 'the'),\n",
              " (',', 'or', 'persuade', 'the', 'listeners.Public'),\n",
              " ('or', 'persuade', 'the', 'listeners.Public', 'speaking'),\n",
              " ('persuade', 'the', 'listeners.Public', 'speaking', 'skills'),\n",
              " ('the', 'listeners.Public', 'speaking', 'skills', 'are'),\n",
              " ('listeners.Public', 'speaking', 'skills', 'are', 'valuable'),\n",
              " ('speaking', 'skills', 'are', 'valuable', 'in'),\n",
              " ('skills', 'are', 'valuable', 'in', 'various'),\n",
              " ('are', 'valuable', 'in', 'various', 'professional'),\n",
              " ('valuable', 'in', 'various', 'professional', 'and'),\n",
              " ('in', 'various', 'professional', 'and', 'personal'),\n",
              " ('various', 'professional', 'and', 'personal', 'settings'),\n",
              " ('professional', 'and', 'personal', 'settings', ','),\n",
              " ('and', 'personal', 'settings', ',', 'including'),\n",
              " ('personal', 'settings', ',', 'including', 'business'),\n",
              " ('settings', ',', 'including', 'business', 'presentations'),\n",
              " (',', 'including', 'business', 'presentations', ','),\n",
              " ('including', 'business', 'presentations', ',', 'conferences'),\n",
              " ('business', 'presentations', ',', 'conferences', ','),\n",
              " ('presentations', ',', 'conferences', ',', 'seminars'),\n",
              " (',', 'conferences', ',', 'seminars', ','),\n",
              " ('conferences', ',', 'seminars', ',', 'academic'),\n",
              " (',', 'seminars', ',', 'academic', 'settings'),\n",
              " ('seminars', ',', 'academic', 'settings', ','),\n",
              " (',', 'academic', 'settings', ',', 'and'),\n",
              " ('academic', 'settings', ',', 'and', 'social'),\n",
              " ('settings', ',', 'and', 'social', 'events'),\n",
              " (',', 'and', 'social', 'events', '.'),\n",
              " ('and', 'social', 'events', '.', 'It'),\n",
              " ('social', 'events', '.', 'It', 'involves'),\n",
              " ('events', '.', 'It', 'involves', 'elements'),\n",
              " ('.', 'It', 'involves', 'elements', 'such'),\n",
              " ('It', 'involves', 'elements', 'such', 'as'),\n",
              " ('involves', 'elements', 'such', 'as', 'speech'),\n",
              " ('elements', 'such', 'as', 'speech', 'preparation'),\n",
              " ('such', 'as', 'speech', 'preparation', ','),\n",
              " ('as', 'speech', 'preparation', ',', 'organization'),\n",
              " ('speech', 'preparation', ',', 'organization', ','),\n",
              " ('preparation', ',', 'organization', ',', 'delivery'),\n",
              " (',', 'organization', ',', 'delivery', ','),\n",
              " ('organization', ',', 'delivery', ',', 'body'),\n",
              " (',', 'delivery', ',', 'body', 'language'),\n",
              " ('delivery', ',', 'body', 'language', ','),\n",
              " (',', 'body', 'language', ',', 'voice'),\n",
              " ('body', 'language', ',', 'voice', 'modulation'),\n",
              " ('language', ',', 'voice', 'modulation', ','),\n",
              " (',', 'voice', 'modulation', ',', 'and'),\n",
              " ('voice', 'modulation', ',', 'and', 'connecting'),\n",
              " ('modulation', ',', 'and', 'connecting', 'with'),\n",
              " (',', 'and', 'connecting', 'with', 'the'),\n",
              " ('and', 'connecting', 'with', 'the', 'audience'),\n",
              " ('connecting', 'with', 'the', 'audience', '.'),\n",
              " ('with', 'the', 'audience', '.', 'Mastering'),\n",
              " ('the', 'audience', '.', 'Mastering', 'public'),\n",
              " ('audience', '.', 'Mastering', 'public', 'speaking'),\n",
              " ('.', 'Mastering', 'public', 'speaking', 'can'),\n",
              " ('Mastering', 'public', 'speaking', 'can', 'help'),\n",
              " ('public', 'speaking', 'can', 'help', 'build'),\n",
              " ('speaking', 'can', 'help', 'build', 'confidence'),\n",
              " ('can', 'help', 'build', 'confidence', ','),\n",
              " ('help', 'build', 'confidence', ',', 'enhance'),\n",
              " ('build', 'confidence', ',', 'enhance', 'communication'),\n",
              " ('confidence', ',', 'enhance', 'communication', 'skills'),\n",
              " (',', 'enhance', 'communication', 'skills', ','),\n",
              " ('enhance', 'communication', 'skills', ',', 'and'),\n",
              " ('communication', 'skills', ',', 'and', 'make'),\n",
              " ('skills', ',', 'and', 'make', 'a'),\n",
              " (',', 'and', 'make', 'a', 'positive'),\n",
              " ('and', 'make', 'a', 'positive', 'impact'),\n",
              " ('make', 'a', 'positive', 'impact', 'on'),\n",
              " ('a', 'positive', 'impact', 'on', 'the'),\n",
              " ('positive', 'impact', 'on', 'the', 'audience'),\n",
              " ('impact', 'on', 'the', 'audience', '.'),\n",
              " ('on', 'the', 'audience', '.', 'Practice'),\n",
              " ('the', 'audience', '.', 'Practice', ','),\n",
              " ('audience', '.', 'Practice', ',', 'preparation'),\n",
              " ('.', 'Practice', ',', 'preparation', ','),\n",
              " ('Practice', ',', 'preparation', ',', 'and'),\n",
              " (',', 'preparation', ',', 'and', 'effective'),\n",
              " ('preparation', ',', 'and', 'effective', 'communication'),\n",
              " (',', 'and', 'effective', 'communication', 'techniques'),\n",
              " ('and', 'effective', 'communication', 'techniques', 'are'),\n",
              " ('effective', 'communication', 'techniques', 'are', 'essential'),\n",
              " ('communication', 'techniques', 'are', 'essential', 'for'),\n",
              " ('techniques', 'are', 'essential', 'for', 'becoming'),\n",
              " ('are', 'essential', 'for', 'becoming', 'a'),\n",
              " ('essential', 'for', 'becoming', 'a', 'proficient'),\n",
              " ('for', 'becoming', 'a', 'proficient', 'public'),\n",
              " ('becoming', 'a', 'proficient', 'public', 'speaker'),\n",
              " ('a', 'proficient', 'public', 'speaker', '.')]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_grams = list(nltk.ngrams(ps_tokens,7))\n",
        "n_grams"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3lcYz-_3Sy71",
        "outputId": "a65830ab-d7b2-49ff-f9d9-50f01fcbbbf9"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Public', 'speaking', 'refers', 'to', 'the', 'act', 'of'),\n",
              " ('speaking', 'refers', 'to', 'the', 'act', 'of', 'delivering'),\n",
              " ('refers', 'to', 'the', 'act', 'of', 'delivering', 'a'),\n",
              " ('to', 'the', 'act', 'of', 'delivering', 'a', 'speech'),\n",
              " ('the', 'act', 'of', 'delivering', 'a', 'speech', 'or'),\n",
              " ('act', 'of', 'delivering', 'a', 'speech', 'or', 'presentation'),\n",
              " ('of', 'delivering', 'a', 'speech', 'or', 'presentation', 'to'),\n",
              " ('delivering', 'a', 'speech', 'or', 'presentation', 'to', 'an'),\n",
              " ('a', 'speech', 'or', 'presentation', 'to', 'an', 'audience'),\n",
              " ('speech', 'or', 'presentation', 'to', 'an', 'audience', 'in'),\n",
              " ('or', 'presentation', 'to', 'an', 'audience', 'in', 'a'),\n",
              " ('presentation', 'to', 'an', 'audience', 'in', 'a', 'formal'),\n",
              " ('to', 'an', 'audience', 'in', 'a', 'formal', 'setting'),\n",
              " ('an', 'audience', 'in', 'a', 'formal', 'setting', '.'),\n",
              " ('audience', 'in', 'a', 'formal', 'setting', '.', 'It'),\n",
              " ('in', 'a', 'formal', 'setting', '.', 'It', 'involves'),\n",
              " ('a', 'formal', 'setting', '.', 'It', 'involves', 'effectively'),\n",
              " ('formal', 'setting', '.', 'It', 'involves', 'effectively', 'communicating'),\n",
              " ('setting', '.', 'It', 'involves', 'effectively', 'communicating', 'ideas'),\n",
              " ('.', 'It', 'involves', 'effectively', 'communicating', 'ideas', ','),\n",
              " ('It',\n",
              "  'involves',\n",
              "  'effectively',\n",
              "  'communicating',\n",
              "  'ideas',\n",
              "  ',',\n",
              "  'information'),\n",
              " ('involves',\n",
              "  'effectively',\n",
              "  'communicating',\n",
              "  'ideas',\n",
              "  ',',\n",
              "  'information',\n",
              "  ','),\n",
              " ('effectively', 'communicating', 'ideas', ',', 'information', ',', 'or'),\n",
              " ('communicating', 'ideas', ',', 'information', ',', 'or', 'messages'),\n",
              " ('ideas', ',', 'information', ',', 'or', 'messages', 'to'),\n",
              " (',', 'information', ',', 'or', 'messages', 'to', 'engage'),\n",
              " ('information', ',', 'or', 'messages', 'to', 'engage', ','),\n",
              " (',', 'or', 'messages', 'to', 'engage', ',', 'inform'),\n",
              " ('or', 'messages', 'to', 'engage', ',', 'inform', ','),\n",
              " ('messages', 'to', 'engage', ',', 'inform', ',', 'or'),\n",
              " ('to', 'engage', ',', 'inform', ',', 'or', 'persuade'),\n",
              " ('engage', ',', 'inform', ',', 'or', 'persuade', 'the'),\n",
              " (',', 'inform', ',', 'or', 'persuade', 'the', 'listeners.Public'),\n",
              " ('inform', ',', 'or', 'persuade', 'the', 'listeners.Public', 'speaking'),\n",
              " (',', 'or', 'persuade', 'the', 'listeners.Public', 'speaking', 'skills'),\n",
              " ('or', 'persuade', 'the', 'listeners.Public', 'speaking', 'skills', 'are'),\n",
              " ('persuade',\n",
              "  'the',\n",
              "  'listeners.Public',\n",
              "  'speaking',\n",
              "  'skills',\n",
              "  'are',\n",
              "  'valuable'),\n",
              " ('the', 'listeners.Public', 'speaking', 'skills', 'are', 'valuable', 'in'),\n",
              " ('listeners.Public',\n",
              "  'speaking',\n",
              "  'skills',\n",
              "  'are',\n",
              "  'valuable',\n",
              "  'in',\n",
              "  'various'),\n",
              " ('speaking', 'skills', 'are', 'valuable', 'in', 'various', 'professional'),\n",
              " ('skills', 'are', 'valuable', 'in', 'various', 'professional', 'and'),\n",
              " ('are', 'valuable', 'in', 'various', 'professional', 'and', 'personal'),\n",
              " ('valuable', 'in', 'various', 'professional', 'and', 'personal', 'settings'),\n",
              " ('in', 'various', 'professional', 'and', 'personal', 'settings', ','),\n",
              " ('various', 'professional', 'and', 'personal', 'settings', ',', 'including'),\n",
              " ('professional', 'and', 'personal', 'settings', ',', 'including', 'business'),\n",
              " ('and',\n",
              "  'personal',\n",
              "  'settings',\n",
              "  ',',\n",
              "  'including',\n",
              "  'business',\n",
              "  'presentations'),\n",
              " ('personal', 'settings', ',', 'including', 'business', 'presentations', ','),\n",
              " ('settings',\n",
              "  ',',\n",
              "  'including',\n",
              "  'business',\n",
              "  'presentations',\n",
              "  ',',\n",
              "  'conferences'),\n",
              " (',', 'including', 'business', 'presentations', ',', 'conferences', ','),\n",
              " ('including',\n",
              "  'business',\n",
              "  'presentations',\n",
              "  ',',\n",
              "  'conferences',\n",
              "  ',',\n",
              "  'seminars'),\n",
              " ('business', 'presentations', ',', 'conferences', ',', 'seminars', ','),\n",
              " ('presentations', ',', 'conferences', ',', 'seminars', ',', 'academic'),\n",
              " (',', 'conferences', ',', 'seminars', ',', 'academic', 'settings'),\n",
              " ('conferences', ',', 'seminars', ',', 'academic', 'settings', ','),\n",
              " (',', 'seminars', ',', 'academic', 'settings', ',', 'and'),\n",
              " ('seminars', ',', 'academic', 'settings', ',', 'and', 'social'),\n",
              " (',', 'academic', 'settings', ',', 'and', 'social', 'events'),\n",
              " ('academic', 'settings', ',', 'and', 'social', 'events', '.'),\n",
              " ('settings', ',', 'and', 'social', 'events', '.', 'It'),\n",
              " (',', 'and', 'social', 'events', '.', 'It', 'involves'),\n",
              " ('and', 'social', 'events', '.', 'It', 'involves', 'elements'),\n",
              " ('social', 'events', '.', 'It', 'involves', 'elements', 'such'),\n",
              " ('events', '.', 'It', 'involves', 'elements', 'such', 'as'),\n",
              " ('.', 'It', 'involves', 'elements', 'such', 'as', 'speech'),\n",
              " ('It', 'involves', 'elements', 'such', 'as', 'speech', 'preparation'),\n",
              " ('involves', 'elements', 'such', 'as', 'speech', 'preparation', ','),\n",
              " ('elements', 'such', 'as', 'speech', 'preparation', ',', 'organization'),\n",
              " ('such', 'as', 'speech', 'preparation', ',', 'organization', ','),\n",
              " ('as', 'speech', 'preparation', ',', 'organization', ',', 'delivery'),\n",
              " ('speech', 'preparation', ',', 'organization', ',', 'delivery', ','),\n",
              " ('preparation', ',', 'organization', ',', 'delivery', ',', 'body'),\n",
              " (',', 'organization', ',', 'delivery', ',', 'body', 'language'),\n",
              " ('organization', ',', 'delivery', ',', 'body', 'language', ','),\n",
              " (',', 'delivery', ',', 'body', 'language', ',', 'voice'),\n",
              " ('delivery', ',', 'body', 'language', ',', 'voice', 'modulation'),\n",
              " (',', 'body', 'language', ',', 'voice', 'modulation', ','),\n",
              " ('body', 'language', ',', 'voice', 'modulation', ',', 'and'),\n",
              " ('language', ',', 'voice', 'modulation', ',', 'and', 'connecting'),\n",
              " (',', 'voice', 'modulation', ',', 'and', 'connecting', 'with'),\n",
              " ('voice', 'modulation', ',', 'and', 'connecting', 'with', 'the'),\n",
              " ('modulation', ',', 'and', 'connecting', 'with', 'the', 'audience'),\n",
              " (',', 'and', 'connecting', 'with', 'the', 'audience', '.'),\n",
              " ('and', 'connecting', 'with', 'the', 'audience', '.', 'Mastering'),\n",
              " ('connecting', 'with', 'the', 'audience', '.', 'Mastering', 'public'),\n",
              " ('with', 'the', 'audience', '.', 'Mastering', 'public', 'speaking'),\n",
              " ('the', 'audience', '.', 'Mastering', 'public', 'speaking', 'can'),\n",
              " ('audience', '.', 'Mastering', 'public', 'speaking', 'can', 'help'),\n",
              " ('.', 'Mastering', 'public', 'speaking', 'can', 'help', 'build'),\n",
              " ('Mastering', 'public', 'speaking', 'can', 'help', 'build', 'confidence'),\n",
              " ('public', 'speaking', 'can', 'help', 'build', 'confidence', ','),\n",
              " ('speaking', 'can', 'help', 'build', 'confidence', ',', 'enhance'),\n",
              " ('can', 'help', 'build', 'confidence', ',', 'enhance', 'communication'),\n",
              " ('help', 'build', 'confidence', ',', 'enhance', 'communication', 'skills'),\n",
              " ('build', 'confidence', ',', 'enhance', 'communication', 'skills', ','),\n",
              " ('confidence', ',', 'enhance', 'communication', 'skills', ',', 'and'),\n",
              " (',', 'enhance', 'communication', 'skills', ',', 'and', 'make'),\n",
              " ('enhance', 'communication', 'skills', ',', 'and', 'make', 'a'),\n",
              " ('communication', 'skills', ',', 'and', 'make', 'a', 'positive'),\n",
              " ('skills', ',', 'and', 'make', 'a', 'positive', 'impact'),\n",
              " (',', 'and', 'make', 'a', 'positive', 'impact', 'on'),\n",
              " ('and', 'make', 'a', 'positive', 'impact', 'on', 'the'),\n",
              " ('make', 'a', 'positive', 'impact', 'on', 'the', 'audience'),\n",
              " ('a', 'positive', 'impact', 'on', 'the', 'audience', '.'),\n",
              " ('positive', 'impact', 'on', 'the', 'audience', '.', 'Practice'),\n",
              " ('impact', 'on', 'the', 'audience', '.', 'Practice', ','),\n",
              " ('on', 'the', 'audience', '.', 'Practice', ',', 'preparation'),\n",
              " ('the', 'audience', '.', 'Practice', ',', 'preparation', ','),\n",
              " ('audience', '.', 'Practice', ',', 'preparation', ',', 'and'),\n",
              " ('.', 'Practice', ',', 'preparation', ',', 'and', 'effective'),\n",
              " ('Practice', ',', 'preparation', ',', 'and', 'effective', 'communication'),\n",
              " (',', 'preparation', ',', 'and', 'effective', 'communication', 'techniques'),\n",
              " ('preparation',\n",
              "  ',',\n",
              "  'and',\n",
              "  'effective',\n",
              "  'communication',\n",
              "  'techniques',\n",
              "  'are'),\n",
              " (',', 'and', 'effective', 'communication', 'techniques', 'are', 'essential'),\n",
              " ('and',\n",
              "  'effective',\n",
              "  'communication',\n",
              "  'techniques',\n",
              "  'are',\n",
              "  'essential',\n",
              "  'for'),\n",
              " ('effective',\n",
              "  'communication',\n",
              "  'techniques',\n",
              "  'are',\n",
              "  'essential',\n",
              "  'for',\n",
              "  'becoming'),\n",
              " ('communication', 'techniques', 'are', 'essential', 'for', 'becoming', 'a'),\n",
              " ('techniques', 'are', 'essential', 'for', 'becoming', 'a', 'proficient'),\n",
              " ('are', 'essential', 'for', 'becoming', 'a', 'proficient', 'public'),\n",
              " ('essential', 'for', 'becoming', 'a', 'proficient', 'public', 'speaker'),\n",
              " ('for', 'becoming', 'a', 'proficient', 'public', 'speaker', '.')]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Stemming\n",
        "from nltk.stem import PorterStemmer\n",
        "pst = PorterStemmer()\n",
        "pst.stem(\"Having\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "gjfd9PEvS23i",
        "outputId": "22cc470d-9617-41a0-e650-260aba21414c"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'have'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words_to_stem = ['give', 'given', 'giving', 'given', 'gave']\n",
        "for words in words_to_stem:\n",
        "  print(word+ \":\" +pst.stem(words))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kHlxBjkOTcYQ",
        "outputId": "463b840f-21fe-4426-b26a-1be457b8b94d"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".:give\n",
            ".:given\n",
            ".:give\n",
            ".:given\n",
            ".:gave\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import LancasterStemmer\n",
        "lst = LancasterStemmer()\n",
        "for word in words_to_stem:\n",
        "  print(words+ \":\" +lst.stem(words))"
      ],
      "metadata": {
        "id": "zV2h19nNWAEh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "459cc67c-4619-43d1-e94e-e94f24dee9b4"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gave:gav\n",
            "gave:gav\n",
            "gave:gav\n",
            "gave:gav\n",
            "gave:gav\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import wordnet\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "word_lem = WordNetLemmatizer()"
      ],
      "metadata": {
        "id": "HrRJCbZ3WAJP"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_lem.lemmatize('corpora')"
      ],
      "metadata": {
        "id": "etlRyKe5WAKb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5dfb295c-d511-4d05-a2a0-6e8940c32ce6"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'corpus'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for words in words_to_stem:\n",
        "  print(words+ \":\" +word_lem.lemmatize(words))"
      ],
      "metadata": {
        "id": "5R4X6gS6WALr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67066f85-71fb-4424-9590-4365685fa69f"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "give:give\n",
            "given:given\n",
            "giving:giving\n",
            "given:given\n",
            "gave:gave\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Stop-words\n",
        "from nltk.corpus import stopwords\n",
        "stopwords.words('english')"
      ],
      "metadata": {
        "id": "H8S3phqPWAPa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d966090a-d2af-485b-dbc0-70c9b1fe567d"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['i',\n",
              " 'me',\n",
              " 'my',\n",
              " 'myself',\n",
              " 'we',\n",
              " 'our',\n",
              " 'ours',\n",
              " 'ourselves',\n",
              " 'you',\n",
              " \"you're\",\n",
              " \"you've\",\n",
              " \"you'll\",\n",
              " \"you'd\",\n",
              " 'your',\n",
              " 'yours',\n",
              " 'yourself',\n",
              " 'yourselves',\n",
              " 'he',\n",
              " 'him',\n",
              " 'his',\n",
              " 'himself',\n",
              " 'she',\n",
              " \"she's\",\n",
              " 'her',\n",
              " 'hers',\n",
              " 'herself',\n",
              " 'it',\n",
              " \"it's\",\n",
              " 'its',\n",
              " 'itself',\n",
              " 'they',\n",
              " 'them',\n",
              " 'their',\n",
              " 'theirs',\n",
              " 'themselves',\n",
              " 'what',\n",
              " 'which',\n",
              " 'who',\n",
              " 'whom',\n",
              " 'this',\n",
              " 'that',\n",
              " \"that'll\",\n",
              " 'these',\n",
              " 'those',\n",
              " 'am',\n",
              " 'is',\n",
              " 'are',\n",
              " 'was',\n",
              " 'were',\n",
              " 'be',\n",
              " 'been',\n",
              " 'being',\n",
              " 'have',\n",
              " 'has',\n",
              " 'had',\n",
              " 'having',\n",
              " 'do',\n",
              " 'does',\n",
              " 'did',\n",
              " 'doing',\n",
              " 'a',\n",
              " 'an',\n",
              " 'the',\n",
              " 'and',\n",
              " 'but',\n",
              " 'if',\n",
              " 'or',\n",
              " 'because',\n",
              " 'as',\n",
              " 'until',\n",
              " 'while',\n",
              " 'of',\n",
              " 'at',\n",
              " 'by',\n",
              " 'for',\n",
              " 'with',\n",
              " 'about',\n",
              " 'against',\n",
              " 'between',\n",
              " 'into',\n",
              " 'through',\n",
              " 'during',\n",
              " 'before',\n",
              " 'after',\n",
              " 'above',\n",
              " 'below',\n",
              " 'to',\n",
              " 'from',\n",
              " 'up',\n",
              " 'down',\n",
              " 'in',\n",
              " 'out',\n",
              " 'on',\n",
              " 'off',\n",
              " 'over',\n",
              " 'under',\n",
              " 'again',\n",
              " 'further',\n",
              " 'then',\n",
              " 'once',\n",
              " 'here',\n",
              " 'there',\n",
              " 'when',\n",
              " 'where',\n",
              " 'why',\n",
              " 'how',\n",
              " 'all',\n",
              " 'any',\n",
              " 'both',\n",
              " 'each',\n",
              " 'few',\n",
              " 'more',\n",
              " 'most',\n",
              " 'other',\n",
              " 'some',\n",
              " 'such',\n",
              " 'no',\n",
              " 'nor',\n",
              " 'not',\n",
              " 'only',\n",
              " 'own',\n",
              " 'same',\n",
              " 'so',\n",
              " 'than',\n",
              " 'too',\n",
              " 'very',\n",
              " 's',\n",
              " 't',\n",
              " 'can',\n",
              " 'will',\n",
              " 'just',\n",
              " 'don',\n",
              " \"don't\",\n",
              " 'should',\n",
              " \"should've\",\n",
              " 'now',\n",
              " 'd',\n",
              " 'll',\n",
              " 'm',\n",
              " 'o',\n",
              " 're',\n",
              " 've',\n",
              " 'y',\n",
              " 'ain',\n",
              " 'aren',\n",
              " \"aren't\",\n",
              " 'couldn',\n",
              " \"couldn't\",\n",
              " 'didn',\n",
              " \"didn't\",\n",
              " 'doesn',\n",
              " \"doesn't\",\n",
              " 'hadn',\n",
              " \"hadn't\",\n",
              " 'hasn',\n",
              " \"hasn't\",\n",
              " 'haven',\n",
              " \"haven't\",\n",
              " 'isn',\n",
              " \"isn't\",\n",
              " 'ma',\n",
              " 'mightn',\n",
              " \"mightn't\",\n",
              " 'mustn',\n",
              " \"mustn't\",\n",
              " 'needn',\n",
              " \"needn't\",\n",
              " 'shan',\n",
              " \"shan't\",\n",
              " 'shouldn',\n",
              " \"shouldn't\",\n",
              " 'wasn',\n",
              " \"wasn't\",\n",
              " 'weren',\n",
              " \"weren't\",\n",
              " 'won',\n",
              " \"won't\",\n",
              " 'wouldn',\n",
              " \"wouldn't\"]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(stopwords.words('english'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WokVwjX-pHVK",
        "outputId": "2b550e25-c94b-4948-94bc-b9f5669ed9ae"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "179"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fdist_top10"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lJGgzF3kpHXg",
        "outputId": "f0a51f62-96cd-4837-b4d2-5651f8c687e4"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(',', 7),\n",
              " ('and', 4),\n",
              " ('ai', 2),\n",
              " ('of', 2),\n",
              " ('.', 2),\n",
              " ('to', 2),\n",
              " ('technologies', 1),\n",
              " ('have', 1),\n",
              " ('a', 1),\n",
              " ('wide', 1)]"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "puntuation = re.compile(r'[-.?!,:;()|0-9]')"
      ],
      "metadata": {
        "id": "xfpP1fkqpHaV"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "post_punctuation = []\n",
        "for words in tokens:\n",
        "  word = puntuation.sub(\"\",words)\n",
        "  if len(word)>0:\n",
        "    post_punctuation.append(word)"
      ],
      "metadata": {
        "id": "6j0zadb6pHc3"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "post_punctuation"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PTGe2UyrpHe8",
        "outputId": "f4f6010f-046e-4875-8695-9ea8b25b29de"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['AI',\n",
              " 'technologies',\n",
              " 'have',\n",
              " 'a',\n",
              " 'wide',\n",
              " 'range',\n",
              " 'of',\n",
              " 'applications',\n",
              " 'including',\n",
              " 'voice',\n",
              " 'assistants',\n",
              " 'image',\n",
              " 'recognition',\n",
              " 'autonomous',\n",
              " 'vehicles',\n",
              " 'recommendation',\n",
              " 'systems',\n",
              " 'fraud',\n",
              " 'detection',\n",
              " 'and',\n",
              " 'much',\n",
              " 'more',\n",
              " 'The',\n",
              " 'field',\n",
              " 'of',\n",
              " 'AI',\n",
              " 'continues',\n",
              " 'to',\n",
              " 'advance',\n",
              " 'rapidly',\n",
              " 'with',\n",
              " 'ongoing',\n",
              " 'research',\n",
              " 'and',\n",
              " 'development',\n",
              " 'to',\n",
              " 'enhance',\n",
              " 'its',\n",
              " 'capabilities',\n",
              " 'and',\n",
              " 'impact',\n",
              " 'across',\n",
              " 'industries',\n",
              " 'and',\n",
              " 'sectors']"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(post_punctuation)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qVn4JK__pHhW",
        "outputId": "3ce6ac48-46ea-46c3-f476-d3fe3be58502"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "45"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# POS (parts of speech)\n",
        "sent = 'Venky is a natural when it comes to drawing'\n",
        "sent_tokens = nltk.word_tokenize(sent)"
      ],
      "metadata": {
        "id": "pxpezf1ApHj7"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for token in sent_tokens:\n",
        "  print(nltk.pos_tag([token]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KqkLczsqpHnX",
        "outputId": "de224f25-4aaf-4b45-d6d1-20b4acc964e2"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('Venky', 'NN')]\n",
            "[('is', 'VBZ')]\n",
            "[('a', 'DT')]\n",
            "[('natural', 'JJ')]\n",
            "[('when', 'WRB')]\n",
            "[('it', 'PRP')]\n",
            "[('comes', 'VBZ')]\n",
            "[('to', 'TO')]\n",
            "[('drawing', 'VBG')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sent1 = 'John is eating a delicious cake'\n",
        "sent1_tokens = nltk.word_tokenize(sent1)\n",
        "for token in sent1_tokens:\n",
        "  print(nltk.pos_tag([token]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VYaI4rXuq2Id",
        "outputId": "51d66cda-32ca-4f91-a3cb-c7fe4a5d036f"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('John', 'NNP')]\n",
            "[('is', 'VBZ')]\n",
            "[('eating', 'VBG')]\n",
            "[('a', 'DT')]\n",
            "[('delicious', 'JJ')]\n",
            "[('cake', 'NN')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# NER (Named Entity Recognition)\n",
        "from nltk import ne_chunk\n",
        "ne_sent = \"The Indian President stays in the Andhra Pradesh\"\n",
        "ne_tokens = nltk.word_tokenize(ne_sent)\n",
        "ne_tags = nltk.pos_tag(ne_tokens)\n",
        "ne_ner = ne_chunk(ne_tags)\n",
        "print(ne_ner)"
      ],
      "metadata": {
        "id": "yDWE7ueMrLXR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b413ee4-1abc-4611-c873-ed857679ca62"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(S\n",
            "  The/DT\n",
            "  (GPE Indian/JJ)\n",
            "  President/NNP\n",
            "  stays/NNS\n",
            "  in/IN\n",
            "  the/DT\n",
            "  (ORGANIZATION Andhra/NNP Pradesh/NNP))\n"
          ]
        }
      ]
    }
  ]
}